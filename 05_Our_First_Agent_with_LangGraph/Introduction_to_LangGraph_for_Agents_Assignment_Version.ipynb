{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJXW_DgiSebM"
      },
      "source": [
        "# LangGraph and LangSmith - Agentic RAG Powered by LangChain\n",
        "\n",
        "In the following notebook we'll complete the following tasks:\n",
        "\n",
        "- ü§ù Breakout Room #1:\n",
        "  1. Install required libraries\n",
        "  2. Set Environment Variables\n",
        "  3. Creating our Tool Belt\n",
        "  4. Creating Our State\n",
        "  5. Creating and Compiling A Graph!\n",
        "\n",
        "- ü§ù Breakout Room #2:\n",
        "  1. Evaluating the LangGraph Application with LangSmith\n",
        "  2. Adding Helpfulness Check and \"Loop\" Limits\n",
        "  3. LangGraph for the \"Patterns\" of GenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djQ3nRAgoF67"
      },
      "source": [
        "# ü§ù Breakout Room #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7pQDUhUnIo8"
      },
      "source": [
        "## Part 1: LangGraph - Building Cyclic Applications with LangChain\n",
        "\n",
        "LangGraph is a tool that leverages LangChain Expression Language to build coordinated multi-actor and stateful applications that includes cyclic behaviour.\n",
        "\n",
        "### Why Cycles?\n",
        "\n",
        "In essence, we can think of a cycle in our graph as a more robust and customizable loop. It allows us to keep our application agent-forward while still giving the powerful functionality of traditional loops.\n",
        "\n",
        "Due to the inclusion of cycles over loops, we can also compose rather complex flows through our graph in a much more readable and natural fashion. Effectively allowing us to recreate application flowcharts in code in an almost 1-to-1 fashion.\n",
        "\n",
        "### Why LangGraph?\n",
        "\n",
        "Beyond the agent-forward approach - we can easily compose and combine traditional \"DAG\" (directed acyclic graph) chains with powerful cyclic behaviour due to the tight integration with LCEL. This means it's a natural extension to LangChain's core offerings!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_fLDElOVoop"
      },
      "source": [
        "## Task 1:  Dependencies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wujPjGJuoPwg"
      },
      "source": [
        "## Task 2: Environment Variables\n",
        "\n",
        "We'll want to set our OpenAI, Tavily, and LangSmith API keys along with our LangSmith environment variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdh8CoVWHRvs",
        "outputId": "3fa78560-393c-4ee5-b871-9886bf0d70f4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jkla2fpx28QK",
        "outputId": "52d7ad22-fcb1-4abe-853b-216c55a12650"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv0glIDyHmRt",
        "outputId": "b69df90a-b4e1-4ddb-9de0-882d98b68ab2"
      },
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE8 - LangGraph - {uuid4().hex[0:8]}\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBRyQmEAVzua"
      },
      "source": [
        "## Task 3: Creating our Tool Belt\n",
        "\n",
        "As is usually the case, we'll want to equip our agent with a toolbelt to help answer questions and add external knowledge.\n",
        "\n",
        "There's a tonne of tools in the [LangChain Community Repo](https://github.com/langchain-ai/langchain-community/tree/main/libs/community) but we'll stick to a couple just so we can observe the cyclic nature of LangGraph in action!\n",
        "\n",
        "We'll leverage:\n",
        "\n",
        "- [Tavily Search Results](https://github.com/langchain-ai/langchain-community/blob/main/libs/community/langchain_community/tools/tavily_search/tool.py)\n",
        "- [Arxiv](https://github.com/langchain-ai/langchain-community/blob/main/libs/community/langchain_community/tools/arxiv/tool.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k6n_Dob2F46"
      },
      "source": [
        "#### üèóÔ∏è Activity #1:\n",
        "\n",
        "Please add the tools to use into our toolbelt.\n",
        "\n",
        "> NOTE: Each tool in our toolbelt should be a method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "lAxaSvlfIeOg"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5)\n",
        "\n",
        "tool_belt = [\n",
        "    tavily_tool,\n",
        "    ArxivQueryRun(),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI-C669ZYVI5"
      },
      "source": [
        "### Model\n",
        "\n",
        "Now we can set-up our model! We'll leverage the familiar OpenAI model suite for this example - but it's not *necessary* to use with LangGraph. LangGraph supports all models - though you might not find success with smaller models - as such, they recommend you stick with:\n",
        "\n",
        "- OpenAI's GPT-3.5 and GPT-4\n",
        "- Anthropic's Claude\n",
        "- Google's Gemini\n",
        "\n",
        "> NOTE: Because we're leveraging the OpenAI function calling API - we'll need to use OpenAI *for this specific example* (or any other service that exposes an OpenAI-style function calling API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "QkNS8rNZJs4z"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugkj3GzuZpQv"
      },
      "source": [
        "Now that we have our model set-up, let's \"put on the tool belt\", which is to say: We'll bind our LangChain formatted tools to the model in an OpenAI function calling format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "4OdMqFafZ_0V"
      },
      "outputs": [],
      "source": [
        "model = model.bind_tools(tool_belt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERzuGo6W18Lr"
      },
      "source": [
        "#### ‚ùì Question #1:\n",
        "\n",
        "How does the model determine which tool to use?\n",
        "\n",
        "##### ‚úÖ Answer:\n",
        "\n",
        "The model uses a list of JSON Schemas that essentialy describes each tool's functionality (including its parameters and outputs). This list of tools is passed to the LLM alongside the user message. Based on this input the LLM then decides if it need to call any of the tools and responds back to the caller (eg. the application) telling which tool(s) needs to be called (executed).\n",
        "LangGraph offers various tools redy to use and abstracts this Tool JSON Schema definition by binding a list of tools to the LLM in use.    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_296Ub96Z_H8"
      },
      "source": [
        "## Task 4: Putting the State in Stateful\n",
        "\n",
        "Earlier we used this phrasing:\n",
        "\n",
        "`coordinated multi-actor and stateful applications`\n",
        "\n",
        "So what does that \"stateful\" mean?\n",
        "\n",
        "To put it simply - we want to have **some kind of object which we can pass around our application that holds information about what the current situation** (state) is. Since our system will be constructed of many parts moving in a coordinated fashion - we want to be able to ensure we have some commonly understood idea of that state.\n",
        "\n",
        "**LangGraph leverages a `StatefulGraph` which uses an `AgentState` object to pass information between the various nodes of the graph.**\n",
        "\n",
        "There are more options than what we'll see below - but this `AgentState` object is one that is stored in a `TypedDict` with the key `messages` and the value is a `Sequence` of `BaseMessages` that will be appended to whenever the state changes.\n",
        "\n",
        "Let's think about a simple example to help understand exactly what this means (we'll simplify a great deal to try and clearly communicate what state is doing):\n",
        "\n",
        "1. We initialize our state object:\n",
        "  - `{\"messages\" : []}`\n",
        "2. Our user submits a query to our application.\n",
        "  - New State: `HumanMessage(#1)`\n",
        "  - `{\"messages\" : [HumanMessage(#1)}`\n",
        "3. We pass our state object to an Agent node which is able to read the current state. It will use the last `HumanMessage` as input. It gets some kind of output which it will add to the state.\n",
        "  - New State: `AgentMessage(#1, additional_kwargs {\"function_call\" : \"WebSearchTool\"})`\n",
        "  - `{\"messages\" : [HumanMessage(#1), AgentMessage(#1, ...)]}`\n",
        "4. We pass our state object to a \"conditional node\" (more on this later) which reads the last state to determine if we need to use a tool - which it can determine properly because of our provided object!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "mxL9b_NZKUdL"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "import operator\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWsMhfO9grLu"
      },
      "source": [
        "## Task 5: It's Graphing Time!\n",
        "\n",
        "**Now that we have state, and we have tools, and we have an LLM - we can finally start making our graph!**\n",
        "\n",
        "Let's take a second to refresh ourselves about what a graph is in this context.\n",
        "\n",
        "Graphs, also called networks in some circles, are a collection of connected objects.\n",
        "\n",
        "The objects in question are typically called nodes, or vertices, and the connections are called edges.\n",
        "\n",
        "Let's look at a simple graph.\n",
        "\n",
        "![image](https://i.imgur.com/2NFLnIc.png)\n",
        "\n",
        "Here, we're using the coloured circles to represent the nodes and the yellow lines to represent the edges. In this case, we're looking at a fully connected graph - where each node is connected by an edge to each other node.\n",
        "\n",
        "If we were to **think about nodes** in the context of LangGraph - we would **think of a function, or an LCEL runnable**.\n",
        "\n",
        "**If we were to think about edges** in the context of LangGraph - we might think of them as \"paths to take\" or **\"where to pass our state object next\"**.\n",
        "\n",
        "Let's create some nodes and expand on our diagram.\n",
        "\n",
        "> NOTE: Due to the tight integration with LCEL - we can comfortably create our nodes in an async fashion!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "91flJWtZLUrl"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "def call_model(state):\n",
        "  messages = state[\"messages\"]\n",
        "  response = model.invoke(messages)\n",
        "  return {\"messages\" : [response]}\n",
        "\n",
        "tool_node = ToolNode(tool_belt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bwR7MgWj3Wg"
      },
      "source": [
        "Now we have two total nodes. We have:\n",
        "\n",
        "- `call_model` is a node that will...well...call the model\n",
        "- `tool_node` is a node which can call a tool\n",
        "\n",
        "Let's start adding nodes! We'll update our diagram along the way to keep track of what this looks like!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vF4_lgtmQNo",
        "outputId": "a4384377-8f7a-415f-be1b-fee6169cb101"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x13a686060>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "uncompiled_graph = StateGraph(AgentState)\n",
        "\n",
        "uncompiled_graph.add_node(\"agent\", call_model)\n",
        "uncompiled_graph.add_node(\"action\", tool_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8CjRlbVmRpW"
      },
      "source": [
        "Let's look at what we have so far:\n",
        "\n",
        "![image](https://i.imgur.com/md7inqG.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaXHpPeSnOWC"
      },
      "source": [
        "Next, we'll add our entrypoint. All our entrypoint does is indicate which node is called first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGCbaYqRnmiw",
        "outputId": "5351807c-2ac7-4316-a3a3-878abeacd114"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x13a686060>"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uncompiled_graph.set_entry_point(\"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUsfGoSpoF9U"
      },
      "source": [
        "![image](https://i.imgur.com/wNixpJe.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q_pQgHmoW0M"
      },
      "source": [
        "Now we want to build a \"conditional edge\" which will use the output state of a node to determine which path to follow.\n",
        "\n",
        "We can help conceptualize this by **thinking of our conditional edge as a conditional in a flowchart!**\n",
        "\n",
        "Notice how our function simply checks if there is a \"function_call\" kwarg present.\n",
        "\n",
        "Then we create an edge where the origin node is our agent node and our destination node is *either* the action node or the END (finish the graph).\n",
        "\n",
        "It's important to highlight that the dictionary passed in as the third parameter (the mapping) should be created with the possible outputs of our conditional function in mind. In this case `should_continue` outputs either `\"end\"` or `\"continue\"` which are subsequently mapped to the action node or the END node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BZgb81VQf9o",
        "outputId": "73a07c15-5f0b-40f2-b033-38b57d056dd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x13a686060>"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def should_continue(state):\n",
        "  last_message = state[\"messages\"][-1]\n",
        "\n",
        "  if last_message.tool_calls:\n",
        "    return \"action\"\n",
        "\n",
        "  return END\n",
        "\n",
        "uncompiled_graph.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    should_continue\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cvhcf4jp0Ce"
      },
      "source": [
        "Let's visualize what this looks like.\n",
        "\n",
        "![image](https://i.imgur.com/8ZNwKI5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKCjWJCkrJb9"
      },
      "source": [
        "Finally, we can add our last edge which will connect our action node to our agent node. This is because we *always* want our action node (which is used to call our tools) to return its output to our agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvcgbHf1rIXZ",
        "outputId": "45d4bdd6-d6bb-4a1d-bb79-cad43c130bf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x13a686060>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uncompiled_graph.add_edge(\"action\", \"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiWDwBQtrw7Z"
      },
      "source": [
        "Let's look at the final visualization.\n",
        "\n",
        "![image](https://i.imgur.com/NWO7usO.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYqDpErlsCsu"
      },
      "source": [
        "All that's left to do now is to compile our workflow - and we're off!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "zt9-KS8DpzNx"
      },
      "outputs": [],
      "source": [
        "simple_agent_graph = uncompiled_graph.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x13a685f30>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#graph visualization    \n",
        "\n",
        "simple_agent_graph #.get_graph().print_ascii()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhNWIwBL1W4Q"
      },
      "source": [
        "#### ‚ùì Question #2:\n",
        "\n",
        "Is there any specific limit to how many times we can cycle?\n",
        "\n",
        "##### ‚úÖ Answer:\n",
        "According to the documentation, by default, LangGraph has a recursion limit of 25 steps. This means your graph can execute a maximum of 25 super-steps during a single run. If your graph reaches this limit without meeting a stop condition, LangGraph will raise a GraphRecursionError. This typically indicates an infinite loop or cycles that don't have proper termination conditions.\n",
        "\n",
        "You can control/change this default by setting the `recursion_limit` param while invoking the graph \n",
        "\n",
        "```\n",
        "graph.invoke(inputs, config={\"recursion_limit\": 100})\n",
        "```\n",
        "\n",
        "If not, how could we impose a limit to the number of cycles?\n",
        "\n",
        "##### ‚úÖ Answer:\n",
        "You can apply the following approaches to impose limits, like:\n",
        " * Counting messages: Since each cycle adds messages to the state, you can count them\n",
        " * Setting a threshold: Define a maximum number of iterations (like 10 in your example)\n",
        " * Forcing termination: Return \"END\" when the limit is reached"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEYcTShCsPaa"
      },
      "source": [
        "## Using Our Graph\n",
        "\n",
        "Now that we've created and compiled our graph - we can call it *just as we'd call any other* `Runnable`!\n",
        "\n",
        "Let's try out a few examples to see how it fairs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn4n37PQRPII",
        "outputId": "5eeedfae-089d-496e-e71f-071939fa5832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='Technical professionals are using AI in various ways to enhance their work, including automating repetitive tasks, improving decision-making, analyzing large datasets, developing new products and services, and optimizing processes. They leverage AI for tasks such as machine learning model development, natural language processing, computer vision, predictive analytics, and automation. This integration helps increase efficiency, accuracy, and innovation across different industries. Would you like specific examples from particular fields or recent trends?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 163, 'total_tokens': 252, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CK4H5jAgvOot908LecVuT2pWqErLd', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e367c824-ba3d-4463-97bf-71cd33d0e368-0', usage_metadata={'input_tokens': 163, 'output_tokens': 89, 'total_tokens': 252, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# Agent initial State\n",
        "inputs = {\"messages\" : [HumanMessage(content=\"How are technical professionals using AI to improve their work?\")]}\n",
        "\n",
        "async for chunk in simple_agent_graph.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        print(values[\"messages\"])\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBHnUtLSscRr"
      },
      "source": [
        "Let's look at what happened:\n",
        "\n",
        "##### ‚úÖ Answer:\n",
        "\n",
        "1. Our state object was populated with our request (*\"How are technical professionals using AI to improve their work?\"*)\n",
        "2. The state object was passed into our **entry point** (agent node);\n",
        "3. The agent node added an `AIMessage` containing its response to the state object and passed it over to the **conditional edge**;\n",
        "6. The conditional edge inspected the state object, could not find the **\"tool_calls\"** in the `additional_kwarg` param and passed the state over to the **END node** finishing the graph execution!\n",
        "\n",
        "##### LangSmith trace for this first run\n",
        "\n",
        "![](./langsmith-trace-no-tools-call.png)\n",
        "\n",
        "Now let's look at an example that shows a multiple tool usage - all with the same flow!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afv2BuEsV5JG",
        "outputId": "ff009536-d281-4a56-c126-9cd245352bfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_KLoE3VnGmhxHpoDgdEIpGV7n', 'function': {'arguments': '{\"query\": \"A Comprehensive Survey of Deep Research\"}', 'name': 'arxiv'}, 'type': 'function'}, {'id': 'call_GnDBengAdTKIs8GKSPJtY7OQ', 'function': {'arguments': '{\"query\": \"author of A Comprehensive Survey of Deep Research\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 182, 'total_tokens': 242, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CK4H6MJAwbIxsHU6oNcR5IdDkB94Y', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5b7d02f4-7f84-43b6-b2b9-56a3cca6162d-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'A Comprehensive Survey of Deep Research'}, 'id': 'call_KLoE3VnGmhxHpoDgdEIpGV7n', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'author of A Comprehensive Survey of Deep Research'}, 'id': 'call_GnDBengAdTKIs8GKSPJtY7OQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 182, 'output_tokens': 60, 'total_tokens': 242, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "Tool Used: arxiv\n",
            "[ToolMessage(content='Published: 2025-06-14\\nTitle: A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\nAuthors: Renjun Xu, Jingwen Peng\\nSummary: This survey examines the rapidly evolving field of Deep Research systems --\\nAI-powered applications that automate complex research workflows through the\\nintegration of large language models, advanced information retrieval, and\\nautonomous reasoning capabilities. We analyze more than 80 commercial and\\nnon-commercial implementations that have emerged since 2023, including\\nOpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and\\nnumerous open-source alternatives. Through comprehensive examination, we\\npropose a novel hierarchical taxonomy that categorizes systems according to\\nfour fundamental technical dimensions: foundation models and reasoning engines,\\ntool utilization and environmental interaction, task planning and execution\\ncontrol, and knowledge synthesis and output generation. We explore the\\narchitectural patterns, implementation approaches, and domain-specific\\nadaptations that characterize these systems across academic, scientific,\\nbusiness, and educational applications. Our analysis reveals both the\\nsignificant capabilities of current implementations and the technical and\\nethical challenges they present regarding information accuracy, privacy,\\nintellectual property, and accessibility. The survey concludes by identifying\\npromising research directions in advanced reasoning architectures, multimodal\\nintegration, domain specialization, human-AI collaboration, and ecosystem\\nstandardization that will likely shape the future evolution of this\\ntransformative technology. By providing a comprehensive framework for\\nunderstanding Deep Research systems, this survey contributes to both the\\ntheoretical understanding of AI-augmented knowledge work and the practical\\ndevelopment of more capable, responsible, and accessible research technologies.\\nThe paper resources can be viewed at\\nhttps://github.com/scienceaix/deepresearch.\\n\\nPublished: 2021-03-05\\nTitle: A comprehensive survey on point cloud registration\\nAuthors: Xiaoshui Huang, Guofeng Mei, Jian Zhang, Rana Abbas\\nSummary: Registration is a transformation estimation problem between two point clouds,\\nwhich has a unique and critical role in numerous computer vision applications.\\nThe developments of optimization-based methods and deep learning methods have\\nimproved registration robustness and efficiency. Recently, the combinations of\\noptimization-based and deep learning methods have further improved performance.\\nHowever, the connections between optimization-based and deep learning methods\\nare still unclear. Moreover, with the recent development of 3D sensors and 3D\\nreconstruction techniques, a new research direction emerges to align\\ncross-source point clouds. This survey conducts a comprehensive survey,\\nincluding both same-source and cross-source registration methods, and summarize\\nthe connections between optimization-based and deep learning methods, to\\nprovide further research insight. This survey also builds a new benchmark to\\nevaluate the state-of-the-art registration algorithms in solving cross-source\\nchallenges. Besides, this survey summarizes the benchmark data sets and\\ndiscusses point cloud registration applications across various domains.\\nFinally, this survey proposes potential research directions in this rapidly\\ngrowing field.\\n\\nPublished: 2023-07-07\\nTitle: A Survey of Deep Learning in Sports Applications: Perception, Comprehension, and Decision\\nAuthors: Zhonghan Zhao, Wenhao Chai, Shengyu Hao, Wenhao Hu, Guanhong Wang, Shidong Cao, Mingli Song, Jenq-Neng Hwang, Gaoang Wang\\nSummary: Deep learning has the potential to revolutionize sports performance, with\\napplications ranging from perception and comprehension to decision. This paper\\npresents a comprehensive survey of deep learning in sports performance,\\nfocusing on three main aspects: algorithms, datasets and virtual environments,\\nand challenges. Firstly, we discuss th', name='arxiv', id='b1d72bd0-e4ce-4b37-9ef2-abf455530f38', tool_call_id='call_KLoE3VnGmhxHpoDgdEIpGV7n'), ToolMessage(content='[{\"title\": \"[2506.12594] A Comprehensive Survey of Deep Research - arXiv\", \"url\": \"https://arxiv.org/abs/2506.12594\", \"content\": \"We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\\\\n\\\\n> cs > arXiv:2506.12594\\\\n\\\\n# Computer Science > Artificial Intelligence\\\\n\\\\narXiv:2506.12594 (cs)\\\\n\\\\n[Submitted on 14 Jun 2025]\\\\n\\\\n# Title:A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\\\n\\\\nAuthors:Renjun Xu, Jingwen Peng [...] View a PDF of the paper titled A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications, by Renjun Xu and 1 other authors [...] View a PDF of the paper titled A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications, by Renjun Xu and 1 other authors\\\\n\\\\n View PDF\\\\n HTML (experimental)\\\\n TeX Source\\\\n Other Formats\\\\n\\\\nview license\\\\n\\\\nCurrent browse context:\\\\n\\\\ncs.AI\\\\n\\\\n< prev\\\\\")    |    next >\\\\\")\\\\n\\\\nnew  |  recent  | 2025-06\\\\n\\\\nChange to browse by:\\\\n\\\\ncs cs.MA\\\\n\\\\n### References & Citations\\\\n\\\\n NASA ADS\\\\n Google Scholar\\\\n Semantic Scholar\\\\n\\\\na export BibTeX citation Loading...\\\\n\\\\n## BibTeX formatted citation\\\\n\\\\n√ó\", \"score\": 0.90289277}, {\"title\": \"GitHub - scienceaix/deepresearch: Awesome Deep Research list ...\", \"url\": \"https://github.com/scienceaix/deepresearch\", \"content\": \"```\\\\n@misc{xu2025comprehensive,\\\\n    title={A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications},\\\\n    author={Renjun Xu and Jingwen Peng},\\\\n    year={2025},\\\\n    eprint={2506.12594},\\\\n    archivePrefix={arXiv},\\\\n    primaryClass={cs.AI}\\\\n}\\\\n```\\\\n\\\\nYou can‚Äôt perform that action at this time.\", \"score\": 0.8991304}, {\"title\": \"A comprehensive survey of deep learning research on medical ...\", \"url\": \"https://pubmed.ncbi.nlm.nih.gov/36462229/\", \"content\": \"PMID: 36462229\\\\n    DOI: 10.1016/j.clinimag.2022.11.003\\\\n\\\\n Item in Clipboard \\\\n\\\\nReview\\\\n\\\\nA comprehensive survey of deep learning research on medical image analysis with focus on transfer learning\\\\n\\\\nSema Atasever et al. Clin Imaging.2023 Feb.\\\\n\\\\nShow details\\\\n\\\\nDisplay options\\\\n\\\\n Display options \\\\n\\\\n Format \\\\n\\\\n Clin Imaging \\\\n\\\\nActions\\\\n\\\\n   Search in PubMed\\\\n   Search in NLM Catalog\\\\n   Add to Search\\\\n\\\\n. 2023 Feb:94:18-41.\\\\n\\\\n doi: 10.1016/j.clinimag.2022.11.003.  Epub 2022 Nov 12. \\\\n\\\\n### Authors [...] A comprehensive survey of deep learning research on medical image analysis with focus on transfer learning\\\\n\\\\nSema Atasever1,Nuh Azginoglu2,Duygu Sinanc Terzi3,Ramazan Terzi4\\\\n\\\\n Affiliations  Expand \\\\n\\\\n### Affiliations [...] Lightweight hybrid transformers-based dyslexia detection using cross-modality data.Sait ARW, Alkhurayyif Y.Sait ARW, et al.Sci Rep. 2025 May 16;15(1):17054. doi: 10.1038/s41598-025-01235-4.Sci Rep. 2025.PMID: 40379688 Free PMC article.\", \"score\": 0.71425}, {\"title\": \"A Comprehensive Survey of Deep Learning Approaches in ...\", \"url\": \"https://www.mdpi.com/1424-8220/25/2/531\", \"content\": \"Elias Dritsas\\\\n\\\\nElias Dritsas\\\\n\\\\nSciProfiles  Scilit  Preprints.org  Google Scholar\\\\n\\\\n \\\\\\\\\\\\n\\\\nIndustrial Systems Institute (ISI), Athena Research and Innovation Center, 26504 Patras, Greece\\\\n\\\\n\\\\\\\\\\\\n\\\\nAuthor to whom correspondence should be addressed.\\\\n\\\\nSensors 2025, 25(2), 531; \\\\n\\\\nSubmission received: 20 December 2024 / Revised: 13 January 2025 / Accepted: 13 January 2025 / Published: 17 January 2025 [...] Visit our dedicated information section to learn more about MDPI.\\\\n\\\\n Get Information\\\\n\\\\nclear\\\\n\\\\n## JSmol Viewer\\\\n\\\\nclear\\\\n\\\\nfirst\\\\\\\\_page\\\\n\\\\n Download PDF \\\\n\\\\nsettings\\\\n\\\\n Order Article Reprints\\\\n\\\\nFont Type:\\\\n\\\\nArial Georgia Verdana\\\\n\\\\nFont Size:\\\\n\\\\nAa Aa Aa\\\\n\\\\nLine Spacing:\\\\n\\\\n\\uf034   \\uf034   \\uf034\\\\n\\\\nColumn Width:\\\\n\\\\n\\uf035   \\uf035   \\uf035\\\\n\\\\nBackground:\\\\n\\\\nOpen AccessReview\\\\n\\\\n# A Comprehensive Survey of Deep Learning Approaches in Image Processing\\\\n\\\\nby \\\\n\\\\nMaria Trigka\\\\n\\\\nMaria Trigka\\\\n\\\\nSciProfiles  Scilit  Preprints.org  Google Scholar\\\\n\\\\nand\", \"score\": 0.65914243}, {\"title\": \"[PDF] A Comprehensive Survey of Deep Research - arXiv\", \"url\": \"https://arxiv.org/pdf/2506.12594?\", \"content\": \"> (2023 - February 2025) Early prototypes and foundational approaches (February - March 2025) Commercial releases and competitive rivalry (March 2025 - Present) Multi-modal integration and diverse applications\\\\n> Google Gemini Deep Research\\\\n> Dec 2024\\\\n> OpenAI Deep Research\\\\n> Feb 2025\\\\n> Manus\\\\n> Mar 2025\\\\n> Perplexity Deep Research\\\\n> Feb 2025\\\\n> AutoGLM-Research\\\\n> Mar 2025\\\\n> QwenLM/ Qwen-Agent\\\\n> Apr 2024\\\\n> n8n\\\\n> 2023 mshumer/ OpenDeepResearcher\\\\n> Feb 2025\\\\n> nickscamara/ open-deep-research [...] Human-AI Collaboration and Standardization 72 9 Conclusion 76 9.1 Key Findings and Contributions 76 9.2 Limitations and Outlook 78 9.3 Broader Implications 79 9.4 Final Thoughts 80 References 81 4 Xu et al. [...] Deep Research demonstrates transformative potential across multiple domains: (1) Academic Innovation: Accelerating hypothesis validation through automated literature synthesis (e.g., HotpotQA [ 307 ] performance benchmarks) and enabling researchers to explore broader inter-disciplinary connections that might otherwise remain undiscovered. The transformative potential of Deep Research extends beyond individual applications to fundamentally reshape scientific discovery processes. As Sourati and\", \"score\": 0.6453216}]', name='tavily_search_results_json', id='34303db1-fd7b-4591-bc79-41af66939d8d', tool_call_id='call_GnDBengAdTKIs8GKSPJtY7OQ', artifact={'query': 'author of A Comprehensive Survey of Deep Research', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://arxiv.org/abs/2506.12594', 'title': '[2506.12594] A Comprehensive Survey of Deep Research - arXiv', 'content': 'We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\\n\\n> cs > arXiv:2506.12594\\n\\n# Computer Science > Artificial Intelligence\\n\\narXiv:2506.12594 (cs)\\n\\n[Submitted on 14 Jun 2025]\\n\\n# Title:A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\n\\nAuthors:Renjun Xu, Jingwen Peng [...] View a PDF of the paper titled A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications, by Renjun Xu and 1 other authors [...] View a PDF of the paper titled A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications, by Renjun Xu and 1 other authors\\n\\n View PDF\\n HTML (experimental)\\n TeX Source\\n Other Formats\\n\\nview license\\n\\nCurrent browse context:\\n\\ncs.AI\\n\\n< prev\")    |    next >\")\\n\\nnew  |  recent  | 2025-06\\n\\nChange to browse by:\\n\\ncs cs.MA\\n\\n### References & Citations\\n\\n NASA ADS\\n Google Scholar\\n Semantic Scholar\\n\\na export BibTeX citation Loading...\\n\\n## BibTeX formatted citation\\n\\n√ó', 'score': 0.90289277, 'raw_content': None}, {'url': 'https://github.com/scienceaix/deepresearch', 'title': 'GitHub - scienceaix/deepresearch: Awesome Deep Research list ...', 'content': '```\\n@misc{xu2025comprehensive,\\n    title={A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications},\\n    author={Renjun Xu and Jingwen Peng},\\n    year={2025},\\n    eprint={2506.12594},\\n    archivePrefix={arXiv},\\n    primaryClass={cs.AI}\\n}\\n```\\n\\nYou can‚Äôt perform that action at this time.', 'score': 0.8991304, 'raw_content': None}, {'url': 'https://pubmed.ncbi.nlm.nih.gov/36462229/', 'title': 'A comprehensive survey of deep learning research on medical ...', 'content': 'PMID: 36462229\\n    DOI: 10.1016/j.clinimag.2022.11.003\\n\\n Item in Clipboard \\n\\nReview\\n\\nA comprehensive survey of deep learning research on medical image analysis with focus on transfer learning\\n\\nSema Atasever et al. Clin Imaging.2023 Feb.\\n\\nShow details\\n\\nDisplay options\\n\\n Display options \\n\\n Format \\n\\n Clin Imaging \\n\\nActions\\n\\n   Search in PubMed\\n   Search in NLM Catalog\\n   Add to Search\\n\\n. 2023 Feb:94:18-41.\\n\\n doi: 10.1016/j.clinimag.2022.11.003.  Epub 2022 Nov 12. \\n\\n### Authors [...] A comprehensive survey of deep learning research on medical image analysis with focus on transfer learning\\n\\nSema Atasever1,Nuh Azginoglu2,Duygu Sinanc Terzi3,Ramazan Terzi4\\n\\n Affiliations  Expand \\n\\n### Affiliations [...] Lightweight hybrid transformers-based dyslexia detection using cross-modality data.Sait ARW, Alkhurayyif Y.Sait ARW, et al.Sci Rep. 2025 May 16;15(1):17054. doi: 10.1038/s41598-025-01235-4.Sci Rep. 2025.PMID: 40379688 Free PMC article.', 'score': 0.71425, 'raw_content': None}, {'url': 'https://www.mdpi.com/1424-8220/25/2/531', 'title': 'A Comprehensive Survey of Deep Learning Approaches in ...', 'content': 'Elias Dritsas\\n\\nElias Dritsas\\n\\nSciProfiles  Scilit  Preprints.org  Google Scholar\\n\\n \\\\\\n\\nIndustrial Systems Institute (ISI), Athena Research and Innovation Center, 26504 Patras, Greece\\n\\n\\\\\\n\\nAuthor to whom correspondence should be addressed.\\n\\nSensors 2025, 25(2), 531; \\n\\nSubmission received: 20 December 2024 / Revised: 13 January 2025 / Accepted: 13 January 2025 / Published: 17 January 2025 [...] Visit our dedicated information section to learn more about MDPI.\\n\\n Get Information\\n\\nclear\\n\\n## JSmol Viewer\\n\\nclear\\n\\nfirst\\\\_page\\n\\n Download PDF \\n\\nsettings\\n\\n Order Article Reprints\\n\\nFont Type:\\n\\nArial Georgia Verdana\\n\\nFont Size:\\n\\nAa Aa Aa\\n\\nLine Spacing:\\n\\n\\uf034   \\uf034   \\uf034\\n\\nColumn Width:\\n\\n\\uf035   \\uf035   \\uf035\\n\\nBackground:\\n\\nOpen AccessReview\\n\\n# A Comprehensive Survey of Deep Learning Approaches in Image Processing\\n\\nby \\n\\nMaria Trigka\\n\\nMaria Trigka\\n\\nSciProfiles  Scilit  Preprints.org  Google Scholar\\n\\nand', 'score': 0.65914243, 'raw_content': None}, {'url': 'https://arxiv.org/pdf/2506.12594?', 'title': '[PDF] A Comprehensive Survey of Deep Research - arXiv', 'content': '> (2023 - February 2025) Early prototypes and foundational approaches (February - March 2025) Commercial releases and competitive rivalry (March 2025 - Present) Multi-modal integration and diverse applications\\n> Google Gemini Deep Research\\n> Dec 2024\\n> OpenAI Deep Research\\n> Feb 2025\\n> Manus\\n> Mar 2025\\n> Perplexity Deep Research\\n> Feb 2025\\n> AutoGLM-Research\\n> Mar 2025\\n> QwenLM/ Qwen-Agent\\n> Apr 2024\\n> n8n\\n> 2023 mshumer/ OpenDeepResearcher\\n> Feb 2025\\n> nickscamara/ open-deep-research [...] Human-AI Collaboration and Standardization 72 9 Conclusion 76 9.1 Key Findings and Contributions 76 9.2 Limitations and Outlook 78 9.3 Broader Implications 79 9.4 Final Thoughts 80 References 81 4 Xu et al. [...] Deep Research demonstrates transformative potential across multiple domains: (1) Academic Innovation: Accelerating hypothesis validation through automated literature synthesis (e.g., HotpotQA [ 307 ] performance benchmarks) and enabling researchers to explore broader inter-disciplinary connections that might otherwise remain undiscovered. The transformative potential of Deep Research extends beyond individual applications to fundamentally reshape scientific discovery processes. As Sourati and', 'score': 0.6453216, 'raw_content': None}], 'response_time': 0.73, 'request_id': '5257bcf2-57c9-4920-b295-d9737122480c'})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='The search for the paper titled \"A Comprehensive Survey of Deep Research\" on arXiv was successful. The paper was published on June 14, 2025, by authors Renjun Xu and Jingwen Peng. \\n\\nRegarding the authors\\' current affiliations, I will now search for each author to find out where they work now.', additional_kwargs={'tool_calls': [{'id': 'call_KkCMjDStnj4I8IMAmz28YoZM', 'function': {'arguments': '{\"query\": \"Renjun Xu\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_33W6hP7hAbNoZ9Tz03sDHlYj', 'function': {'arguments': '{\"query\": \"Jingwen Peng\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 125, 'prompt_tokens': 2520, 'total_tokens': 2645, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CK4H8XDs9NUtdqg3tQJBUpLcY7OmI', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--3352e56f-ab4d-487b-b526-3a8a90654b03-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Renjun Xu'}, 'id': 'call_KkCMjDStnj4I8IMAmz28YoZM', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Jingwen Peng'}, 'id': 'call_33W6hP7hAbNoZ9Tz03sDHlYj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2520, 'output_tokens': 125, 'total_tokens': 2645, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "Tool Used: tavily_search_results_json\n",
            "[ToolMessage(content='[{\"title\": \"Renjun Xu - Researcher, Zhejiang University - OpenReview\", \"url\": \"https://openreview.net/profile?id=~Renjun_Xu1\", \"content\": \"# Renjun Xu\\\\n\\\\n### Principal Researcher, Zhejiang University\\\\n\\\\n Joined September 2021\\\\n\\\\n#### Names\\\\n\\\\nRenjun Xu (Preferred)\\\\n\\\\n Suggest Name\\\\n\\\\n#### Emails\\\\n\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\@zju.edu.cn (Confirmed)\\\\n\\\\n Suggest Email\\\\n\\\\n#### Personal Links\\\\n\\\\nHomepage\\\\n\\\\nDBLP\\\\n\\\\nORCID\\\\n\\\\nSemantic Scholar\\\\n\\\\n Suggest URL\\\\n\\\\n#### Career & Education History\\\\n\\\\nPrincipal Researcher\\\\n\\\\nZhejiang University(zju.edu.cn)\\\\n\\\\n2018 ‚Äì Present\\\\n\\\\n Suggest Position\\\\n\\\\n#### Advisors, Relations & Conflicts\\\\n\\\\nNo relations added\\\\n\\\\n Suggest Relation\\\\n\\\\n#### Expertise [...] equivariant neural network, domain adaptation, domain generalization, molecular, physics, contrastive learning, symmetry, crystal, phase transition\\\\n\\\\nPresent\\\\n\\\\n Suggest Expertise\", \"score\": 0.7154444}, {\"title\": \"Renyuan Xu Honored with Prestigious NSF CAREER Award\", \"url\": \"https://viterbischool.usc.edu/news/2024/06/renyuan-xu-honored-with-prestigious-nsf-career-award/\", \"content\": \"Xu is an emerging research leader who harnesses machine learning and probability tools to improve decision-making in fields that experience a high degree of uncertainty, such as the financial and economic systems, or in public policy, such as the design of fair contracts and the allocation of social resources. [...] WiSE Gabilan Assistant Professor of Industrial and Systems Engineering Renyuan Xu has been recognized with the prestigious National Science Foundation (NSF) CAREER Award for 2024.\\u202fThe award honors early-career faculty members with the potential to serve as academic role models in research and education to lead advances in their respective fields. The NSF selects CAREER Award recipients who are building a firm foundation for a lifetime of leadership in integrating education and research. [...] Xu joined the Daniel J. Epstein Department of Industrial and Systems Engineering in 2021 following a two-year role as a Hooke Research Fellow at Oxford University‚Äôs Mathematical Institute.\\\\n\\\\nShe completed her undergraduate studies in mathematics at the University of Science and Technology of China before moving to the U.S. for her Ph.D. at UC Berkeley in the Department of Industrial Engineering and Operations Research.\", \"score\": 0.6501347}, {\"title\": \"Renjun Xu - DBLP\", \"url\": \"https://dblp.org/pid/269/4621\", \"content\": \"Joint Declaration: The freedom of science is at the heart of liberal, democratic societies. Without this freedom, it is impossible for scientific efforts to be geared toward gaining knowledge and facts. It is therefore extremely worrying that the scientific freedom is coming under increasing pressure in various regions of the world. (read more)\\\\n\\\\ndefault search action\\\\n\\\\nask others\\\\n\\\\n Google\\\\n Google Scholar\\\\n Semantic Scholar\\\\n Internet Archive Scholar\\\\n CiteSeerX\\\\n ORCID\\\\n\\\\n# Renjun Xu [...] For some months now, the dblp team has been receiving an exceptionally high number of support and error correction requests from the community. While we are grateful and happy to process all incoming emails, please assume that it will currently take us several weeks, if not months, to read and address your request. Most importantly, please refrain from sending your request multiple times. This will not advance your issue and will only complicate and extend the time required to address it. Thank [...] > Home > Persons\\\\n\\\\n## Person information\\\\n\\\\n## Other persons with a similar name\\\\n\\\\nsee FAQ\\\\n\\\\n Why are some names followed by a four digit number?\\\\n\\\\n Ren-Jung Xu\\\\n\\\\n## SPARQL queries\\\\n\\\\nrun query for this person\\\\n\\\\n highly cited coauthors\\\\n co-cited other authors\\\\n non-coauthors with many coauthors in common\\\\n highly cited publications\\\\n co-cited publications\\\\n authors citing this author\\\\n number of authors per paper\\\\n\\\\nor build your own?\\\\n\\\\n## Refine list\\\\n\\\\nrefinements active!\\\\n\\\\nzoomed in on ?? of ?? records\", \"score\": 0.6222074}, {\"title\": \"Renjun Xu - Center for Data Science, Zhejiang University | ‰∫∫ÊâçÁîªÂÉè\", \"url\": \"https://www.aminer.cn/profile/renjun-xu/53f42ceddabfaedd74d30355?source=bz1\", \"content\": \"Renjun Xu - Center for Data Science, Zhejiang University | ‰∫∫ÊâçÁîªÂÉè - AMiner\\\\n\\\\n\\\\n\\\\nResearch\\\\n\\\\nCenter for Data Science Zhejiang University\\\\n\\\\n„ÄÅ„ÄäInternational Joint Conference on Artificial Intelligence„Äã(IJCAI, CCF-A), „ÄäIEEE Transactions on Knowledge and Data Engineering„Äã(TKDE, CCF-A)‰∫§ÂèâÈ¢ÜÂüüÂèëË°®Â§öÁØáÂõΩÈôÖÈ°∂Â∞ñÊúüÂàäÂíå‰ºöËÆÆÊñáÁ´†ÔºåCVPR„ÄÅAAAI„ÄÅNIPS„ÄÅTPAMI„ÄÅTIP„ÄÅTLTÁ≠âÈ°∂Á∫ß‰∫∫Â∑•Êô∫ËÉΩÊúüÂàäÂíå‰ºöËÆÆÁ®ãÂ∫èÂßîÂëò‰ºöÂßîÂëòÔºåËç£Ëé∑2020Âπ¥Â∫¶‰∏ñÁïå‰∫∫Â∑•Êô∫ËÉΩÂ§ß‰ºöÈùíÂπ¥‰ºòÁßÄËÆ∫ÊñáÊèêÂêçÂ•ñÔºåÊåáÂØºÂπ∂Êé®ËçêÁöÑÊâÄÊúâÂ≠¶ÁîüÂùáÂ∑≤ÊãøÂà∞È∫ªÁúÅÁêÜÂ∑•Â≠¶Èô¢(MIT)„ÄÅÂç°ÂÜÖÂü∫Ê¢ÖÈöÜÂ§ßÂ≠¶(CMU)Á≠âÂÖ®ÁêÉÈ°∂Â∞ñÂêçÊ†°ÁöÑofferÔºÅ\\\\n\\\\nEducation\\\\n\\\\nSign in to view more\\\\n\\\\nExperience\\\\n\\\\nSign in to view more [...] Research Interests\\\\n\\\\n2012 2025\\\\n\\\\nPapers ÂÖ± 39 ÁØá Patents ÂÖ± 9 ÁØá Author Statistics Co-Author Similar Experts\\\\n\\\\nBy Year By Citation ‰∏ªÈ¢òÁ≠õÈÄâ ÊúüÂàäÁ∫ßÂà´Á≠õÈÄâ Âêà‰ΩúËÄÖÁ≠õÈÄâ Âêà‰ΩúÊú∫ÊûÑÁ≠õÈÄâ\\\\n\\\\nÊó∂Èó¥\\\\n\\\\nÂºïÁî®Èáè\\\\n\\\\n‰∏ªÈ¢ò\\\\n\\\\nÊúüÂàäÁ∫ßÂà´\\\\n\\\\nÂêà‰ΩúËÄÖ\\\\n\\\\nÂêà‰ΩúÊú∫ÊûÑ\\\\n\\\\nAll 2025 2024 2023 2022 2021 2020 2015 2014 2013 2012 2010 2006\\\\n\\\\nDo PhD-level LLMs Truly Grasp Elementary Addition? Probing Rule Learning Vs. Memorization in Large Language Models\\\\n\\\\nYang Yan,Yu Lu,Renjun Xu,Zhenzhong Lan\\\\n\\\\narXiv ¬∑ Computation and LanguageÔºà2025Ôºâ\\\\n\\\\nCited 0 Views 11 Bibtex\\\\n\\\\n0\\\\n\\\\n11 [...] The page data are from open Internet sources, cooperative publishers and automatic analysis results through AI technology. We do not make any commitments and guarantees for the validity, accuracy, correctness, reliability, completeness and timeliness of the page data. If you have any questions, please contact us by email: report@aminer.cn\\\\n\\\\nSwipe to Fine Result\", \"score\": 0.60049355}, {\"title\": \"Renjun Hu\\'s Homepage\", \"url\": \"https://hurenjun.github.io/\", \"content\": \"various business domains including feed recommendation, user growth, online marketing, and LLM-as-a-Judge. Since January 2025, he has joined the School of Data Science and Engineering, East China Normal University as a young researcher. His recent research interests include robust machine learning and the understanding, evaluation, and applications of large language models. [...] Renjun Hu received his Bachelor\\'s degree in 2014 and Ph.D. in 2020 from the School of Computer Science and Engineering at Beihang University. From September 2017 to April 2018, he was a joint Ph.D. student in the Data Mining Group at Rutgers University. He then worked as a research intern at the Business Intelligence Lab of Baidu Research from May 2018 to September 2019. During 2020 to 2024, he served as an algorithm engineer at Alibaba Cloud, contributing to AI-driven transformations across [...] Young Researcher, East China Normal University, January 2025 - present\\\\n Algorithm engineer, Alibaba Group, July 2020 - January 2025\\\\n Research intern, Baidu Business Intelligence Lab, May 2018 - September 2019\\\\n Visiting student, Rutgers University, September 2017 - April 2018\", \"score\": 0.5760895}]', name='tavily_search_results_json', id='a3341d06-98e8-45b5-a51b-c69cc5cc832e', tool_call_id='call_KkCMjDStnj4I8IMAmz28YoZM', artifact={'query': 'Renjun Xu', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://openreview.net/profile?id=~Renjun_Xu1', 'title': 'Renjun Xu - Researcher, Zhejiang University - OpenReview', 'content': '# Renjun Xu\\n\\n### Principal Researcher, Zhejiang University\\n\\n Joined September 2021\\n\\n#### Names\\n\\nRenjun Xu (Preferred)\\n\\n Suggest Name\\n\\n#### Emails\\n\\n\\\\\\\\\\\\\\\\@zju.edu.cn (Confirmed)\\n\\n Suggest Email\\n\\n#### Personal Links\\n\\nHomepage\\n\\nDBLP\\n\\nORCID\\n\\nSemantic Scholar\\n\\n Suggest URL\\n\\n#### Career & Education History\\n\\nPrincipal Researcher\\n\\nZhejiang University(zju.edu.cn)\\n\\n2018 ‚Äì Present\\n\\n Suggest Position\\n\\n#### Advisors, Relations & Conflicts\\n\\nNo relations added\\n\\n Suggest Relation\\n\\n#### Expertise [...] equivariant neural network, domain adaptation, domain generalization, molecular, physics, contrastive learning, symmetry, crystal, phase transition\\n\\nPresent\\n\\n Suggest Expertise', 'score': 0.7154444, 'raw_content': None}, {'url': 'https://viterbischool.usc.edu/news/2024/06/renyuan-xu-honored-with-prestigious-nsf-career-award/', 'title': 'Renyuan Xu Honored with Prestigious NSF CAREER Award', 'content': 'Xu is an emerging research leader who harnesses machine learning and probability tools to improve decision-making in fields that experience a high degree of uncertainty, such as the financial and economic systems, or in public policy, such as the design of fair contracts and the allocation of social resources. [...] WiSE Gabilan Assistant Professor of Industrial and Systems Engineering Renyuan Xu has been recognized with the prestigious National Science Foundation (NSF) CAREER Award for 2024.\\u202fThe award honors early-career faculty members with the potential to serve as academic role models in research and education to lead advances in their respective fields. The NSF selects CAREER Award recipients who are building a firm foundation for a lifetime of leadership in integrating education and research. [...] Xu joined the Daniel J. Epstein Department of Industrial and Systems Engineering in 2021 following a two-year role as a Hooke Research Fellow at Oxford University‚Äôs Mathematical Institute.\\n\\nShe completed her undergraduate studies in mathematics at the University of Science and Technology of China before moving to the U.S. for her Ph.D. at UC Berkeley in the Department of Industrial Engineering and Operations Research.', 'score': 0.6501347, 'raw_content': None}, {'url': 'https://dblp.org/pid/269/4621', 'title': 'Renjun Xu - DBLP', 'content': 'Joint Declaration: The freedom of science is at the heart of liberal, democratic societies. Without this freedom, it is impossible for scientific efforts to be geared toward gaining knowledge and facts. It is therefore extremely worrying that the scientific freedom is coming under increasing pressure in various regions of the world. (read more)\\n\\ndefault search action\\n\\nask others\\n\\n Google\\n Google Scholar\\n Semantic Scholar\\n Internet Archive Scholar\\n CiteSeerX\\n ORCID\\n\\n# Renjun Xu [...] For some months now, the dblp team has been receiving an exceptionally high number of support and error correction requests from the community. While we are grateful and happy to process all incoming emails, please assume that it will currently take us several weeks, if not months, to read and address your request. Most importantly, please refrain from sending your request multiple times. This will not advance your issue and will only complicate and extend the time required to address it. Thank [...] > Home > Persons\\n\\n## Person information\\n\\n## Other persons with a similar name\\n\\nsee FAQ\\n\\n Why are some names followed by a four digit number?\\n\\n Ren-Jung Xu\\n\\n## SPARQL queries\\n\\nrun query for this person\\n\\n highly cited coauthors\\n co-cited other authors\\n non-coauthors with many coauthors in common\\n highly cited publications\\n co-cited publications\\n authors citing this author\\n number of authors per paper\\n\\nor build your own?\\n\\n## Refine list\\n\\nrefinements active!\\n\\nzoomed in on ?? of ?? records', 'score': 0.6222074, 'raw_content': None}, {'url': 'https://www.aminer.cn/profile/renjun-xu/53f42ceddabfaedd74d30355?source=bz1', 'title': 'Renjun Xu - Center for Data Science, Zhejiang University | ‰∫∫ÊâçÁîªÂÉè', 'content': 'Renjun Xu - Center for Data Science, Zhejiang University | ‰∫∫ÊâçÁîªÂÉè - AMiner\\n\\n\\n\\nResearch\\n\\nCenter for Data Science Zhejiang University\\n\\n„ÄÅ„ÄäInternational Joint Conference on Artificial Intelligence„Äã(IJCAI, CCF-A), „ÄäIEEE Transactions on Knowledge and Data Engineering„Äã(TKDE, CCF-A)‰∫§ÂèâÈ¢ÜÂüüÂèëË°®Â§öÁØáÂõΩÈôÖÈ°∂Â∞ñÊúüÂàäÂíå‰ºöËÆÆÊñáÁ´†ÔºåCVPR„ÄÅAAAI„ÄÅNIPS„ÄÅTPAMI„ÄÅTIP„ÄÅTLTÁ≠âÈ°∂Á∫ß‰∫∫Â∑•Êô∫ËÉΩÊúüÂàäÂíå‰ºöËÆÆÁ®ãÂ∫èÂßîÂëò‰ºöÂßîÂëòÔºåËç£Ëé∑2020Âπ¥Â∫¶‰∏ñÁïå‰∫∫Â∑•Êô∫ËÉΩÂ§ß‰ºöÈùíÂπ¥‰ºòÁßÄËÆ∫ÊñáÊèêÂêçÂ•ñÔºåÊåáÂØºÂπ∂Êé®ËçêÁöÑÊâÄÊúâÂ≠¶ÁîüÂùáÂ∑≤ÊãøÂà∞È∫ªÁúÅÁêÜÂ∑•Â≠¶Èô¢(MIT)„ÄÅÂç°ÂÜÖÂü∫Ê¢ÖÈöÜÂ§ßÂ≠¶(CMU)Á≠âÂÖ®ÁêÉÈ°∂Â∞ñÂêçÊ†°ÁöÑofferÔºÅ\\n\\nEducation\\n\\nSign in to view more\\n\\nExperience\\n\\nSign in to view more [...] Research Interests\\n\\n2012 2025\\n\\nPapers ÂÖ± 39 ÁØá Patents ÂÖ± 9 ÁØá Author Statistics Co-Author Similar Experts\\n\\nBy Year By Citation ‰∏ªÈ¢òÁ≠õÈÄâ ÊúüÂàäÁ∫ßÂà´Á≠õÈÄâ Âêà‰ΩúËÄÖÁ≠õÈÄâ Âêà‰ΩúÊú∫ÊûÑÁ≠õÈÄâ\\n\\nÊó∂Èó¥\\n\\nÂºïÁî®Èáè\\n\\n‰∏ªÈ¢ò\\n\\nÊúüÂàäÁ∫ßÂà´\\n\\nÂêà‰ΩúËÄÖ\\n\\nÂêà‰ΩúÊú∫ÊûÑ\\n\\nAll 2025 2024 2023 2022 2021 2020 2015 2014 2013 2012 2010 2006\\n\\nDo PhD-level LLMs Truly Grasp Elementary Addition? Probing Rule Learning Vs. Memorization in Large Language Models\\n\\nYang Yan,Yu Lu,Renjun Xu,Zhenzhong Lan\\n\\narXiv ¬∑ Computation and LanguageÔºà2025Ôºâ\\n\\nCited 0 Views 11 Bibtex\\n\\n0\\n\\n11 [...] The page data are from open Internet sources, cooperative publishers and automatic analysis results through AI technology. We do not make any commitments and guarantees for the validity, accuracy, correctness, reliability, completeness and timeliness of the page data. If you have any questions, please contact us by email: report@aminer.cn\\n\\nSwipe to Fine Result', 'score': 0.60049355, 'raw_content': None}, {'url': 'https://hurenjun.github.io/', 'title': \"Renjun Hu's Homepage\", 'content': \"various business domains including feed recommendation, user growth, online marketing, and LLM-as-a-Judge. Since January 2025, he has joined the School of Data Science and Engineering, East China Normal University as a young researcher. His recent research interests include robust machine learning and the understanding, evaluation, and applications of large language models. [...] Renjun Hu received his Bachelor's degree in 2014 and Ph.D. in 2020 from the School of Computer Science and Engineering at Beihang University. From September 2017 to April 2018, he was a joint Ph.D. student in the Data Mining Group at Rutgers University. He then worked as a research intern at the Business Intelligence Lab of Baidu Research from May 2018 to September 2019. During 2020 to 2024, he served as an algorithm engineer at Alibaba Cloud, contributing to AI-driven transformations across [...] Young Researcher, East China Normal University, January 2025 - present\\n Algorithm engineer, Alibaba Group, July 2020 - January 2025\\n Research intern, Baidu Business Intelligence Lab, May 2018 - September 2019\\n Visiting student, Rutgers University, September 2017 - April 2018\", 'score': 0.5760895, 'raw_content': None}], 'response_time': 1.49, 'request_id': '121c5c7a-2a9b-494d-bd3b-971527c4f847'}), ToolMessage(content='[{\"title\": \"Jingwen Peng Email & Phone Number | Manulife Lead Analyst ...\", \"url\": \"https://rocketreach.co/jingwen-peng-email_28909123\", \"content\": \"Jingwen Peng, based in Boston, Massachusetts, United States, is currently a Lead Analyst, Investment Analytics at Manulife Investment Management at Manulife. Jingwen Peng brings experience from previous roles at Manulife Asset Management, Congress Asset Management and Prelude Asset Management. Jingwen Peng holds a 2008 - 2009 Master of Arts in Mathematical Finance @ Boston University Questrom School of Business. With a robust skill set that includes Quantitative Finance, Asset Management, [...] - [x]  see more  \\\\n   2010 - 2012 Research Analyst @ Congress Asset Management\\\\n   2009 - 2010 Research Analyst @ Prelude Asset Management\\\\n   2007 - 2007 Intern Analyst @ Bank of China\\\\n\\\\n see less  \\\\n\\\\n### Jingwen Peng Education\\\\n\\\\n   Boston University Questrom School of Business \\\\nMaster of Arts ( Mathematical Finance)\\\\n\\\\n2008 - 2009\\\\n   Peking University \\\\nBachelor of Science ( Mathematics with a concerntration in Financial Mathematics)\\\\n\\\\n2004 - 2008\\\\n\\\\n### Jingwen Peng Skills [...] Image 7: Liberty Mutual Investments Employee Jingwen Peng\\'s profile photo ### Jingwen Peng #### Director II - Lead Data Steward at Liberty Mutual Investments Boston, MA, US   View \\\\n\\\\n2\\\\n       hotmail.com\\\\n       libertymutualgroup.com\\\\n\\\\n   \\\\nImage 8: Manulife Employee Pragashini Fox\\'s profile photo ### Jingwen Peng #### Product owner at Bpifrance Assurance Export Pontoise, FR   View \\\\n\\\\n1\\\\n       bpifrance.fr\\\\n\\\\nView Similar Profiles\\\\n\\\\nTop Manulife Employees\", \"score\": 0.90869105}, {\"title\": \"US-China veterinary program at K-State celebrates graduating class ...\", \"url\": \"https://www.k-state.edu/media/newsreleases/2024-06/US-China-joint-veterinary-program-at-KState-celebrates-graduating-class-and-homecoming-event.html\", \"content\": \"of Missouri.At the homecoming event, recent graduates, current students and friends presented about their experiences in veterinary college. One student\\'s experiences included a close brush with a Kansas weather phenomenon.\\\\\"In my fourth year, I learned that I love dental procedures,\\\\\" said Jingwen Peng, a K-State Doctor of Veterinary Medicine graduate. \\\\\"While on the equine field service, I did dental [exams] on horses, mules and donkeys. Also while on equine field service, I got a bonus view of [...] ###### The recent graduates of the U.S.-China Joint Doctor of Veterinary Medicine Program received purple stethoscopes after giving presentations about their educational experiences. From left: Lei Wang, program manager for the U.S.-China Center for Animal Health, graduates Yuanjue Tan, Xingy Tang, Xiang Yu, Cong Zhu, Jingwen Peng and Hodes Family Dean Bonnie Rush. | Download this photo. [...] \\\\\"Great challenges lie in front of us, but that also comes with great possibilities. I think we have learned from the best, and now is the best time to go back to our country to witness and, more importantly, be part of the growing and developing of veterinary medicine in China.\\\\\"In addition to Peng and Tang, the May 2024 Doctor of Veterinary Medicine graduates are Xiangyu Lin from Kansas State University and Dr. Cong Zhu from the University of Minnesota. The Chinese graduates of the program will\", \"score\": 0.69622743}, {\"title\": \"Jingwen Peng - U of Rochester Simon STEM MSBA - LinkedIn\", \"url\": \"https://www.linkedin.com/in/jpeng19\", \"content\": \"‚óè\\\\tAuthored product requirement documentation, followed up on new features and optimization based on customer feedback.\\\\n\\\\n‚óè\\\\tDevised creative short videos content, elevated ad CTR by 4 times on Google Ads and refined data-driven strategies.\\\\n\\\\n‚óè\\\\tGrew social media presence through influencer marketing, acquired 1,000+ new users on Instagram, FB, and YouTube. [...] At Amazon, my role as a Site Merchandising analyst was pivotal in enhancing the Kindle E-book business through data-driven strategies<br><br> By automating reports and refining forecasting models, our team significantly improved operational efficiency and influenced strategic decisions that positively impacted the growth of E-book store and Kindle Unlimited<br><br> My technical acumen, particularly in Excel, SQL and Python, was instrumental in automating processes, reducing manual workloads, [...] ## Experience\\\\n### Marketing Analyst  \\\\nEmpire City Casino  \\\\nMay 2025 - Present   \\\\nYonkers, New York, United States  \\\\n\\\\n### Amazon  \\\\nAmazon  \\\\nN/A - Present   \\\\nBeijing, China  \\\\n\\\\n### Marketing Analyst  \\\\nJiyuzhoutian Information Technology  \\\\nApr 2019 - Sep 2019   \\\\nBeijing, China  \\\\n‚óè\\\\tSEO for website CouponBirds and ASO for app Spark, improved CTR by 50%, enhancing visibility and user acquisition.\", \"score\": 0.6301622}, {\"title\": \"Jingwen Peng - Loop\", \"url\": \"https://loop.frontiersin.org/people/1381593/overview\", \"content\": \"0 Edited Research Topics\\\\n 0 Edited Publications\\\\n 0 Reviewed Publications\\\\n\\\\nView Editorial Contributions\\\\n\\\\n## Editorial Roles\\\\n\\\\nThis researcher does not have an active role on a Frontiers editorial board. You may recommend their participation\\\\nhere.\\\\n\\\\n 0\\\\n\\\\n  Followers\\\\n 0\\\\n\\\\n  Following\\\\n\\\\nNo content to display.\\\\n\\\\nView All Followers\\\\n\\\\nNo content to display.\\\\n\\\\nView All Following [...] Jingwen Peng\\\\n\\\\n Overview\\\\n Bio\\\\n Network0\\\\n Publications4\\\\n Editorial Contributions0\\\\n Impact\\\\n\\\\n 6,420Total\\\\n    \\\\n  Views\\\\n 14Profile  \\\\n  Views\\\\n 4Total  \\\\n  Publications\\\\n 6,406Publication  \\\\n  Views\\\\n 3,182Publications  \\\\n  Downloads\\\\n\\\\nView Full Impact\\\\n\\\\n## Brief Bio\\\\n\\\\nUsers who add a description significantly increase their chances for discovers and collaboration. Showcase your career and increase your impact by\\\\nadding your brief bio now.\\\\n\\\\nNo content to display.\\\\n\\\\nView Full Bio and Expertise\\\\n\\\\n## 4 Publications [...] Frontiers In and Loop are registered trade marks of Frontiers Media SA.  \\\\n¬© Copyright 2007-2025 Frontiers Media SA. All rights reserved -\\\\nTerms and Conditions\", \"score\": 0.49523994}, {\"title\": \"[PDF] SCHWARZMAN SCHOLARS CLASS OF 2018\", \"url\": \"https://www.schwarzmanscholars.org/wp-content/uploads/2020/05/Schwarzman-Scholars-Class-of-2018-profiles-126-Scholars.pdf\", \"content\": \"Jingwen SUN graduated in May 2017 from the National University of Singapore with a Bachelor‚Äôs degree in Computing and Business. She is passionate about innovation and entrepreneurship. She has worked with venture capital funds in Israel and China and also worked with Accenture and Analysys Mason as an analyst intern. Jingwen is excited to join the Schwarzman Scholars program to learn more about leadership within a global context. Jingwen is 23 years old and from China. JONATHAN PADILLA UNITED [...] Assistant at Purdue, supporting both domestic and international students, and served as Vice President of Alpha Kappa Psi. She most recently worked in the Risk Assurance practice at PricewaterhouseCoopers in Chicago. At Schwarzman College, she aspires to amplify her leadership and business skills as both a humanitarian and an entrepreneur to improve and empower the education of youth in developing regions. Jing is 24 years old and from China. JINGWEN SUN CHINA NATIONAL UNIVERSITY OF SINGAPORE\", \"score\": 0.38366494}]', name='tavily_search_results_json', id='41a0c8f9-4f68-460b-a228-ce7bfb73168b', tool_call_id='call_33W6hP7hAbNoZ9Tz03sDHlYj', artifact={'query': 'Jingwen Peng', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://rocketreach.co/jingwen-peng-email_28909123', 'title': 'Jingwen Peng Email & Phone Number | Manulife Lead Analyst ...', 'content': \"Jingwen Peng, based in Boston, Massachusetts, United States, is currently a Lead Analyst, Investment Analytics at Manulife Investment Management at Manulife. Jingwen Peng brings experience from previous roles at Manulife Asset Management, Congress Asset Management and Prelude Asset Management. Jingwen Peng holds a 2008 - 2009 Master of Arts in Mathematical Finance @ Boston University Questrom School of Business. With a robust skill set that includes Quantitative Finance, Asset Management, [...] - [x]  see more  \\n   2010 - 2012 Research Analyst @ Congress Asset Management\\n   2009 - 2010 Research Analyst @ Prelude Asset Management\\n   2007 - 2007 Intern Analyst @ Bank of China\\n\\n see less  \\n\\n### Jingwen Peng Education\\n\\n   Boston University Questrom School of Business \\nMaster of Arts ( Mathematical Finance)\\n\\n2008 - 2009\\n   Peking University \\nBachelor of Science ( Mathematics with a concerntration in Financial Mathematics)\\n\\n2004 - 2008\\n\\n### Jingwen Peng Skills [...] Image 7: Liberty Mutual Investments Employee Jingwen Peng's profile photo ### Jingwen Peng #### Director II - Lead Data Steward at Liberty Mutual Investments Boston, MA, US   View \\n\\n2\\n       hotmail.com\\n       libertymutualgroup.com\\n\\n   \\nImage 8: Manulife Employee Pragashini Fox's profile photo ### Jingwen Peng #### Product owner at Bpifrance Assurance Export Pontoise, FR   View \\n\\n1\\n       bpifrance.fr\\n\\nView Similar Profiles\\n\\nTop Manulife Employees\", 'score': 0.90869105, 'raw_content': None}, {'url': 'https://www.k-state.edu/media/newsreleases/2024-06/US-China-joint-veterinary-program-at-KState-celebrates-graduating-class-and-homecoming-event.html', 'title': 'US-China veterinary program at K-State celebrates graduating class ...', 'content': 'of Missouri.At the homecoming event, recent graduates, current students and friends presented about their experiences in veterinary college. One student\\'s experiences included a close brush with a Kansas weather phenomenon.\"In my fourth year, I learned that I love dental procedures,\" said Jingwen Peng, a K-State Doctor of Veterinary Medicine graduate. \"While on the equine field service, I did dental [exams] on horses, mules and donkeys. Also while on equine field service, I got a bonus view of [...] ###### The recent graduates of the U.S.-China Joint Doctor of Veterinary Medicine Program received purple stethoscopes after giving presentations about their educational experiences. From left: Lei Wang, program manager for the U.S.-China Center for Animal Health, graduates Yuanjue Tan, Xingy Tang, Xiang Yu, Cong Zhu, Jingwen Peng and Hodes Family Dean Bonnie Rush. | Download this photo. [...] \"Great challenges lie in front of us, but that also comes with great possibilities. I think we have learned from the best, and now is the best time to go back to our country to witness and, more importantly, be part of the growing and developing of veterinary medicine in China.\"In addition to Peng and Tang, the May 2024 Doctor of Veterinary Medicine graduates are Xiangyu Lin from Kansas State University and Dr. Cong Zhu from the University of Minnesota. The Chinese graduates of the program will', 'score': 0.69622743, 'raw_content': None}, {'url': 'https://www.linkedin.com/in/jpeng19', 'title': 'Jingwen Peng - U of Rochester Simon STEM MSBA - LinkedIn', 'content': '‚óè\\tAuthored product requirement documentation, followed up on new features and optimization based on customer feedback.\\n\\n‚óè\\tDevised creative short videos content, elevated ad CTR by 4 times on Google Ads and refined data-driven strategies.\\n\\n‚óè\\tGrew social media presence through influencer marketing, acquired 1,000+ new users on Instagram, FB, and YouTube. [...] At Amazon, my role as a Site Merchandising analyst was pivotal in enhancing the Kindle E-book business through data-driven strategies<br><br> By automating reports and refining forecasting models, our team significantly improved operational efficiency and influenced strategic decisions that positively impacted the growth of E-book store and Kindle Unlimited<br><br> My technical acumen, particularly in Excel, SQL and Python, was instrumental in automating processes, reducing manual workloads, [...] ## Experience\\n### Marketing Analyst  \\nEmpire City Casino  \\nMay 2025 - Present   \\nYonkers, New York, United States  \\n\\n### Amazon  \\nAmazon  \\nN/A - Present   \\nBeijing, China  \\n\\n### Marketing Analyst  \\nJiyuzhoutian Information Technology  \\nApr 2019 - Sep 2019   \\nBeijing, China  \\n‚óè\\tSEO for website CouponBirds and ASO for app Spark, improved CTR by 50%, enhancing visibility and user acquisition.', 'score': 0.6301622, 'raw_content': None}, {'url': 'https://loop.frontiersin.org/people/1381593/overview', 'title': 'Jingwen Peng - Loop', 'content': '0 Edited Research Topics\\n 0 Edited Publications\\n 0 Reviewed Publications\\n\\nView Editorial Contributions\\n\\n## Editorial Roles\\n\\nThis researcher does not have an active role on a Frontiers editorial board. You may recommend their participation\\nhere.\\n\\n 0\\n\\n  Followers\\n 0\\n\\n  Following\\n\\nNo content to display.\\n\\nView All Followers\\n\\nNo content to display.\\n\\nView All Following [...] Jingwen Peng\\n\\n Overview\\n Bio\\n Network0\\n Publications4\\n Editorial Contributions0\\n Impact\\n\\n 6,420Total\\n    \\n  Views\\n 14Profile  \\n  Views\\n 4Total  \\n  Publications\\n 6,406Publication  \\n  Views\\n 3,182Publications  \\n  Downloads\\n\\nView Full Impact\\n\\n## Brief Bio\\n\\nUsers who add a description significantly increase their chances for discovers and collaboration. Showcase your career and increase your impact by\\nadding your brief bio now.\\n\\nNo content to display.\\n\\nView Full Bio and Expertise\\n\\n## 4 Publications [...] Frontiers In and Loop are registered trade marks of Frontiers Media SA.  \\n¬© Copyright 2007-2025 Frontiers Media SA. All rights reserved -\\nTerms and Conditions', 'score': 0.49523994, 'raw_content': None}, {'url': 'https://www.schwarzmanscholars.org/wp-content/uploads/2020/05/Schwarzman-Scholars-Class-of-2018-profiles-126-Scholars.pdf', 'title': '[PDF] SCHWARZMAN SCHOLARS CLASS OF 2018', 'content': 'Jingwen SUN graduated in May 2017 from the National University of Singapore with a Bachelor‚Äôs degree in Computing and Business. She is passionate about innovation and entrepreneurship. She has worked with venture capital funds in Israel and China and also worked with Accenture and Analysys Mason as an analyst intern. Jingwen is excited to join the Schwarzman Scholars program to learn more about leadership within a global context. Jingwen is 23 years old and from China. JONATHAN PADILLA UNITED [...] Assistant at Purdue, supporting both domestic and international students, and served as Vice President of Alpha Kappa Psi. She most recently worked in the Risk Assurance practice at PricewaterhouseCoopers in Chicago. At Schwarzman College, she aspires to amplify her leadership and business skills as both a humanitarian and an entrepreneur to improve and empower the education of youth in developing regions. Jing is 24 years old and from China. JINGWEN SUN CHINA NATIONAL UNIVERSITY OF SINGAPORE', 'score': 0.38366494, 'raw_content': None}], 'response_time': 2.38, 'request_id': '2815197d-f0c2-496f-97de-22650d8cca63'})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='Renjun Xu is currently a Principal Researcher at Zhejiang University. \\n\\nJingwen Peng is currently a Lead Analyst at Manulife Investment Management.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 6489, 'total_tokens': 6520, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CK4HE7YREq3iVd4dB3gAXzeKp11z6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--418390b1-4f0c-445b-8a8e-83e1f9c28945-0', usage_metadata={'input_tokens': 6489, 'output_tokens': 31, 'total_tokens': 6520, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"messages\" : [HumanMessage(content=\"Search Arxiv for the A Comprehensive Survey of Deep Research paper, then search each of the authors to find out where they work now using Tavily!\")]}\n",
        "\n",
        "async for chunk in simple_agent_graph.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        if node == \"action\":\n",
        "          print(f\"Tool Used: {values['messages'][0].name}\")\n",
        "        print(values[\"messages\"])\n",
        "\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Langsmith trace with tools call\n",
        "\n",
        "![](./langsmith-trace-with-tools-call.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXzDlZVz1Hnf"
      },
      "source": [
        "#### üèóÔ∏è Activity #2:\n",
        "\n",
        "Please write out the steps the agent took to arrive at the correct answer.\n",
        "\n",
        "##### ‚úÖ Answer:\n",
        "\n",
        "1. The Agent received our input message (`HumanMessage`) - *\"Search Arxiv for the A Comprehensive Survey of Deep Research paper, ...\"*\n",
        "2. The Agent then passed the input message to the Model\n",
        "3. The Model responded (`AIMesage`) with a list of tools (*Arxivix* and *Tavily Search*)\n",
        "4. The Agent passed the message to the **Conditional Edge** (`should_continue`), which checked for the `tool_calls` key and decided to go to the Action node\n",
        "5. The Action node then called the tools in order: 1st the Arxivix; 2nd the Tavily Search\n",
        "6. The agent passed te tools'output to the Model, which in turn responded witht he final answer.\n",
        "7. The final response was passed on to the Conditional Edge (`should_continue`), which checked for the `tool_calls` key and decided to END the flow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§ù Breakout Room #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7c8-Uyarh1v"
      },
      "source": [
        "## Part 1: LangSmith Evaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV3XeFOT1Sar"
      },
      "source": [
        "### Pre-processing for LangSmith"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wruQCuzewUuO"
      },
      "source": [
        "To do a little bit more preprocessing, let's wrap our LangGraph agent in a simple chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "orYxBZXSxJjZ",
        "outputId": "76be837b-6424-4516-8f63-07fbd8c25bf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'answer': 'Deep Research typically refers to an in-depth and comprehensive investigation or analysis into a specific subject or field. It involves thorough data collection, critical evaluation, and detailed examination to uncover insights, understand complex issues, or develop new knowledge. Deep Research is often used in academic, scientific, technological, and business contexts to inform decision-making, innovation, and strategic planning. \\n\\nIf you are referring to a specific organization, product, or platform named \"Deep Research,\" please provide more context so I can give a more precise answer.'}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def convert_inputs(input_object):\n",
        "  return {\"messages\" : [HumanMessage(content=input_object[\"text\"])]}\n",
        "\n",
        "def parse_output(input_state):\n",
        "  return {\"answer\" : input_state[\"messages\"][-1].content}\n",
        "\n",
        "agent_chain_with_formatting = convert_inputs | simple_agent_graph | parse_output\n",
        "\n",
        "agent_chain_with_formatting.invoke({\"text\" : \"What is Deep Research?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9UkCIqkpyZu"
      },
      "source": [
        "### Task 1: Creating An Evaluation Dataset\n",
        "\n",
        "Just as we saw last week, we'll want to create a dataset to test our Agent's ability to answer questions.\n",
        "\n",
        "In order to do this - we'll want to provide some questions and some answers. Let's look at how we can create such a dataset below.\n",
        "\n",
        "```python\n",
        "questions = [\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"Who were the main authors on the 'A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications' paper?\"},\n",
        "        \"outputs\" : {\"must_mention\" : [\"Peng\", \"Xu\"]}   \n",
        "    },\n",
        "    ...,\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"Where do the authors of the 'A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications' work now?\"},\n",
        "        \"outputs\" : {\"must_mention\" : [\"Zhejiang\", \"Liberty Mutual\"]}\n",
        "    }\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfMXF2KAsQxs"
      },
      "source": [
        "#### üèóÔ∏è Activity #3:\n",
        "\n",
        "Please create a dataset in the above format with at least 5 questions that pertain to the cohort use-case (more information [here](https://www.notion.so/Session-4-RAG-with-LangGraph-OSS-Local-Models-Eval-w-LangSmith-26acd547af3d80838d5beba464d7e701#26acd547af3d81d08809c9c82a462bdd)), or the use-case you're hoping to tackle in your Demo Day project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "CbagRuJop83E"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"Search Arxiv for How people use ChatGPT Research paper, then search the web to find out how people use ChatGPT in their daily work using Tavily!\"},\n",
        "        \"outputs\" : {\"must_mention\" : [\"emails\", \"reports\", \"spreadsheets\", \"documents\", \"presentations\"]}\n",
        "    },\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"What are the most common ways people use AI in their work?\"},\n",
        "        \"outputs\" : {\"must_mention\" : [\"emails\", \"reports\", \"spreadsheets\", \"documents\", \"presentations\"]}\n",
        "    },\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"Do people use AI for their personal lives?\"},\n",
        "        \"outputs\" : {\"must_mention\" : [\"productivity\", \"creativity\", \"learning\", \"health\", \"fitness\"]}\n",
        "    },\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"What concerns or challenges do people have when using AI?\"},\n",
        "        \"outputs\" : {\"must_mention\" : [\"Privacy\", \"biases\", \"security\", \"trust\", \"governance\"]}\n",
        "    },\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"I'm an AI Engineer focusing on building intelligent agentic systems. Currently, I'm involved in a local Christian Church located in North Texas, USA. I'm also always looking to help my kids (currently Elementary and Middle Schoolers) get more engaged with their learning. What should I build to add value to the local communities I‚Äôm engaged in?\"},\n",
        "        \"outputs\" : {\"must_mention\" : [\"Core Features\", \"MVP\", \"AI Agent\", \"LLM\", \"Problem it Solves\", \"Value Proposition\"]}\n",
        "    },\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"What AI powered Solutions are available for Legacy Application Modernizaton and Migration?\"},\n",
        "        \"outputs\" : {\"must_mention\" : [\"business logic\", \"technology stack\", \"dependencies\", \"analysis\"]}\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7QVFuAmsh7L"
      },
      "source": [
        "Now we can add our dataset to our LangSmith project using the following code which we saw last Thursday!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "RLfrZrgSsn85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'example_ids': ['4a136c30-f852-47f9-8fd2-aa2d53278af6',\n",
              "  '32460a59-89c8-4ee4-a18a-2ea8c37c8cbc',\n",
              "  'fbafd7bf-ba62-4e5c-b5d7-1628229a670f',\n",
              "  'a0b5c308-8f9a-4ae1-a28f-5c2f0e302d5c',\n",
              "  'de4691ed-c067-4980-adad-6476c3ebf960',\n",
              "  '9e3888ad-d681-49b9-ba74-cc65bbf8ac43'],\n",
              " 'count': 6}"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()\n",
        "\n",
        "dataset_name = f\"Simple Search Agent - Evaluation Dataset - {uuid4().hex[0:8]}\"\n",
        "\n",
        "dataset = client.create_dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    description=\"Questions about the cohort use-case to evaluate the Simple Search Agent.\"\n",
        ")\n",
        "\n",
        "client.create_examples(\n",
        "    dataset_id=dataset.id,\n",
        "    examples=questions\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lRTXUrTtP9Y"
      },
      "source": [
        "### Task 2: Adding Evaluators\n",
        "\n",
        "Let's use the OpenEvals library to product an evaluator that we can then pass into LangSmith!\n",
        "\n",
        "> NOTE: Examine the `CORRECTNESS_PROMPT` below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are an expert data labeler evaluating model outputs for correctness. Your task is to assign a score based on the following rubric:\n",
            "\n",
            "<Rubric>\n",
            "  A correct answer:\n",
            "  - Provides accurate and complete information\n",
            "  - Contains no factual errors\n",
            "  - Addresses all parts of the question\n",
            "  - Is logically consistent\n",
            "  - Uses precise and accurate terminology\n",
            "\n",
            "  When scoring, you should penalize:\n",
            "  - Factual errors or inaccuracies\n",
            "  - Incomplete or partial answers\n",
            "  - Misleading or ambiguous statements\n",
            "  - Incorrect terminology\n",
            "  - Logical inconsistencies\n",
            "  - Missing key information\n",
            "</Rubric>\n",
            "\n",
            "<Instructions>\n",
            "  - Carefully read the input and output\n",
            "  - Check for factual accuracy and completeness\n",
            "  - Focus on correctness of information rather than style or verbosity\n",
            "</Instructions>\n",
            "\n",
            "<Reminder>\n",
            "  The goal is to evaluate factual correctness and completeness of the response.\n",
            "</Reminder>\n",
            "\n",
            "<input>\n",
            "{inputs}\n",
            "</input>\n",
            "\n",
            "<output>\n",
            "{outputs}\n",
            "</output>\n",
            "\n",
            "Use the reference outputs below to help you evaluate the correctness of the response:\n",
            "\n",
            "<reference_outputs>\n",
            "{reference_outputs}\n",
            "</reference_outputs>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from openevals.prompts import CORRECTNESS_PROMPT\n",
        "print(CORRECTNESS_PROMPT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "QrAUXMFftlAY"
      },
      "outputs": [],
      "source": [
        "from openevals.llm import create_llm_as_judge\n",
        "\n",
        "correctness_evaluator = create_llm_as_judge(\n",
        "        prompt=CORRECTNESS_PROMPT,\n",
        "        model=\"openai:o3-mini\", # very impactful to the final score\n",
        "        feedback_key=\"correctness\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's also create a custom Evaluator for our created dataset above - we do this by first making a simple Python function!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "def must_mention(inputs: dict, outputs: dict, reference_outputs: dict) -> float:\n",
        "  # determine if the phrases in the reference_outputs are in the outputs\n",
        "  required = reference_outputs.get(\"must_mention\") or []\n",
        "  score = all(phrase in outputs[\"answer\"] for phrase in required)\n",
        "  return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNtHORUh0jZY"
      },
      "source": [
        "#### ‚ùì Question #4:\n",
        "\n",
        "What are some ways you could improve this metric as-is?\n",
        "\n",
        "> NOTE: Alternatively you can suggest where gaps exist in this method.\n",
        "\n",
        "##### ‚úÖ Answer:\n",
        "###### Ways to Improve This Metric\n",
        "The current metric logic implementation is a simple **binary evaluation** metric. Here a re some ways to improve it:\n",
        "\n",
        " * **Add Partial Credit Scoring**: the current metric is binary (0 or 1), but you could provide partial credit.\n",
        " \n",
        " * **Add Fuzzy Matching**: use fuzzy string matching to handle variations, typos, and synonyms.\n",
        " \n",
        " * **Add Semantic Similarity**: use embeddings to check for semantic similarity rather than exact string matching.\n",
        " \n",
        " * **Add Context Awareness**: consider the context around the mentions.\n",
        "\n",
        "###### Gaps in the Current Method\n",
        "1. **No Handling of Synonyms or Variations**\n",
        "  * \"emails\" vs \"email\" vs \"electronic mail\"\n",
        "  * \"AI\" vs \"artificial intelligence\"\n",
        "  * Case sensitivity issues\n",
        "2. **Binary Scoring is Too Rigid**\n",
        "  * All-or-nothing approach doesn't reflect partial correctness\n",
        "  * Doesn't account for quality of mentions\n",
        "3. **No Context Consideration**\n",
        "  * Doesn't distinguish between positive and negative mentions\n",
        "  * Ignores the semantic meaning around the mention\n",
        "4. **Limited to Exact String Matching**\n",
        "  * Misses paraphrases or rephrased concepts\n",
        "  * No semantic understanding\n",
        "5. **No Confidence Scoring**\n",
        "  * Doesn't provide insight into how confident the metric is\n",
        "  * No explanation for why something scored low\n",
        "6. **No Weighted Importance**\n",
        "  * All required mentions treated equally\n",
        "  * Some concepts might be more important than others"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1RJr349zhv7"
      },
      "source": [
        "Task 3: Evaluating\n",
        "\n",
        "All that is left to do is evaluate our agent's response!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "efcf57067cf743d8b4ce059a61cbe02e",
            "53e33aae3b97490c82aec7bbb0d6ebba",
            "ad84e0e971d3455db2efe7dd0d1f803e",
            "72adef9b70dd48198b7322b6c5b113cf",
            "8a61d045ffd44ac58f3f13eb10044836",
            "041e22a9b5514e36bd4d1dac01d5d398",
            "886d762f2a7c421382efb5502c6d42a1",
            "ab91fd625bbd43afbf8c6398193a88d0",
            "716557ad09874dcb989d75f7c74424cd",
            "77d4c0ebaae045b58efc4f789c9a2360",
            "0d622ccc56264fac8fd7508dbdbe6e29"
          ]
        },
        "id": "p5TeCUUkuGld",
        "outputId": "2f7d62a2-e78d-447a-d07b-f9e4d500fb79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for experiment: 'simple_agent, baseline-320802a6' at:\n",
            "https://smith.langchain.com/o/bb9a3dd7-ec88-4998-a3cb-7a19da336bd6/datasets/3fb042a1-78c8-4b00-b143-66bad3d5fad3/compare?selectedSessions=5170b6f7-abf4-4f88-9cf8-ef26809bb573\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "906eeb348d68409fbcb6f8328bd7cc53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results = client.evaluate(\n",
        "    agent_chain_with_formatting,\n",
        "    data=dataset.name,\n",
        "    evaluators=[correctness_evaluator, must_mention],\n",
        "    experiment_prefix=\"simple_agent, baseline\",  # optional, experiment name prefix\n",
        "    description=\"Testing the baseline system.\",  # optional, experiment description\n",
        "    max_concurrency=4, # optional, add concurrency\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Eval results before metric improvements**\n",
        "\n",
        "![Eval results](./langsmith-dataset-eval-1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Improve the eval metric function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "from difflib import SequenceMatcher\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from openai import OpenAI\n",
        "\n",
        "def must_mention_improved(inputs: dict, outputs: dict, reference_outputs: dict) -> float:\n",
        "    required = reference_outputs.get(\"must_mention\") or []\n",
        "    if not required:\n",
        "        return 1.0\n",
        "    \n",
        "    answer = outputs[\"answer\"].lower()\n",
        "    matches = sum(1 for phrase in required if phrase.lower() in answer)\n",
        "    return matches / len(required)  # Returns 0.0 to 1.0\n",
        "\n",
        "def must_mention_fuzzy(inputs: dict, outputs: dict, reference_outputs: dict) -> float:\n",
        "    required = reference_outputs.get(\"must_mention\") or []\n",
        "    answer = outputs[\"answer\"].lower()\n",
        "    \n",
        "    total_score = 0\n",
        "    for phrase in required:\n",
        "        phrase_lower = phrase.lower()\n",
        "        best_match = 0\n",
        "        \n",
        "        # Check exact match first\n",
        "        if phrase_lower in answer:\n",
        "            best_match = 1.0\n",
        "        else:\n",
        "            # Try fuzzy matching on word boundaries\n",
        "            words = answer.split()\n",
        "            for i in range(len(words) - len(phrase_lower.split()) + 1):\n",
        "                candidate = \" \".join(words[i:i+len(phrase_lower.split())])\n",
        "                similarity = SequenceMatcher(None, phrase_lower, candidate).ratio()\n",
        "                best_match = max(best_match, similarity)\n",
        "        \n",
        "        total_score += best_match\n",
        "    \n",
        "    return total_score / len(required) if required else 1.0\n",
        "\n",
        "llm_client = OpenAI()\n",
        "def get_embedding(text: str) -> List[float]:\n",
        "\n",
        "    embedding = llm_client.embeddings.create(\n",
        "        input=text, model=\"text-embedding-3-small\"\n",
        "    )\n",
        "\n",
        "    return embedding.data[0].embedding\n",
        "\n",
        "def must_mention_semantic(inputs: dict, outputs: dict, reference_outputs: dict) -> float:\n",
        "    required = reference_outputs.get(\"must_mention\") or []\n",
        "    answer = outputs[\"answer\"]\n",
        "    \n",
        "    if not required:\n",
        "        return 1.0\n",
        "    \n",
        "    # Get embeddings for required phrases and answer\n",
        "    required_embeddings = model.encode(required)\n",
        "    answer_embedding = model.encode([answer])\n",
        "    \n",
        "    # Calculate cosine similarity\n",
        "    similarities = np.dot(required_embeddings, answer_embedding.T).flatten()\n",
        "    \n",
        "    # Use threshold for semantic matching (e.g., 0.7)\n",
        "    matches = np.sum(similarities > 0.7)\n",
        "    return matches / len(required)\n",
        "\n",
        "\n",
        "def must_mention_contextual(inputs: dict, outputs: dict, reference_outputs: dict) -> float:\n",
        "    required = reference_outputs.get(\"must_mention\") or []\n",
        "    answer = outputs[\"answer\"].lower()\n",
        "    \n",
        "    if not required:\n",
        "        return 1.0\n",
        "    \n",
        "    total_score = 0\n",
        "    for phrase in required:\n",
        "        phrase_lower = phrase.lower()\n",
        "        if phrase_lower in answer:\n",
        "            # Find context around the mention\n",
        "            phrase_index = answer.find(phrase_lower)\n",
        "            context_start = max(0, phrase_index - 50)\n",
        "            context_end = min(len(answer), phrase_index + len(phrase_lower) + 50)\n",
        "            context = answer[context_start:context_end]\n",
        "            \n",
        "            # Check if context suggests positive mention (vs negative)\n",
        "            positive_words = [\"good\", \"effective\", \"useful\", \"important\", \"valuable\"]\n",
        "            negative_words = [\"bad\", \"ineffective\", \"useless\", \"unimportant\", \"problematic\"]\n",
        "            \n",
        "            context_score = 1.0\n",
        "            if any(word in context for word in negative_words):\n",
        "                context_score = 0.5\n",
        "            elif any(word in context for word in positive_words):\n",
        "                context_score = 1.2\n",
        "            \n",
        "            total_score += min(context_score, 1.0)\n",
        "        else:\n",
        "            total_score += 0\n",
        "    \n",
        "    return total_score / len(required)\n",
        "\n",
        "\n",
        "def comprehensive_mention_evaluator(inputs: dict, outputs: dict, reference_outputs: dict) -> dict:\n",
        "    required = reference_outputs.get(\"must_mention\") or []\n",
        "    \n",
        "    return {\n",
        "        \"exact_match\": must_mention(inputs, outputs, reference_outputs),\n",
        "        \"partial_credit\": must_mention_improved(inputs, outputs, reference_outputs),\n",
        "        \"fuzzy_match\": must_mention_fuzzy(inputs, outputs, reference_outputs),\n",
        "        \"semantic_similarity\": must_mention_semantic(inputs, outputs, reference_outputs),\n",
        "        \"contextual\": must_mention_contextual(inputs, outputs, reference_outputs)\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Reevaluate with new metric score functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for experiment: 'multi_metric_evaluation-0f2999dc' at:\n",
            "https://smith.langchain.com/o/bb9a3dd7-ec88-4998-a3cb-7a19da336bd6/datasets/c7dfcd2c-50ea-4c77-a69b-f5a3b331559c/compare?selectedSessions=798f1066-78c6-4f6c-8ad8-89b3880fe126\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e8267e519974509aa226f14acb784c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Then use them in your evaluation\n",
        "results = client.evaluate(\n",
        "    agent_chain_with_formatting,\n",
        "    data=dataset.name,\n",
        "    evaluators=[\n",
        "        correctness_evaluator,\n",
        "        must_mention_improved,\n",
        "        must_mention_fuzzy, \n",
        "        must_mention_contextual\n",
        "    ],\n",
        "    experiment_prefix=\"multi_metric_evaluation\",\n",
        "    description=\"Testing with multiple evaluation metrics\",\n",
        "    max_concurrency=4,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Eval results after metric improvements**\n",
        "\n",
        "![Eval results](./langsmith-dataset-eval-multiple-score-metric-func.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see in the above results (*from LangSmith Datasets & Experiments dashboard*), the `must_mention_fuzzy` score metric seems to be a better way to evaluate the output in our scenario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhTNe4kWrplB"
      },
      "source": [
        "## Part 2: LangGraph with Helpfulness:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1wKRddbIY_S"
      },
      "source": [
        "### Task 3: Adding Helpfulness Check and \"Loop\" Limits\n",
        "\n",
        "Now that we've done evaluation - **let's see if we can add an extra step where we review the content we've generated to confirm if it fully answers the user's query!**\n",
        "\n",
        "We're going to make a few key adjustments to account for this:\n",
        "\n",
        "1. We're going to add an artificial limit on how many \"loops\" the agent can go through - this will help us to avoid the potential situation where we never exit the loop.\n",
        "2. We'll add to our existing conditional edge to obtain the behaviour we desire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npTYJ8ayR5B3"
      },
      "source": [
        "First, let's define our state again - we can check the length of the state object, so we don't need additional state for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "-LQ84YhyJG0w"
      },
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "  # The add_messages reducer function defines how new messages should be added to this list.\n",
        "  # It concatenates the new messages to the existing messages list, maintaining the chronological order\n",
        "  messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD7EV0HqSQcb"
      },
      "source": [
        "Now we can set our graph up! This process will be almost entirely the same - with the inclusion of one additional node/conditional edge!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oajBwLkFVi1N"
      },
      "source": [
        "#### üèóÔ∏è Activity #4:\n",
        "\n",
        "Please write markdown for the following cells to explain what each is doing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ‚úÖ Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6rN7feNVn9f"
      },
      "source": [
        "Lets define a new Graph by adding our existing Nodes:\n",
        " * `call_model` responsible for calling the LLM and;\n",
        " * `tool_node` responsible to executing out tools (according to the LLM response tools parameter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r6XXA5FJbVf",
        "outputId": "ff713041-e498-4f0f-a875-a03502b87729"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x13b297bf0>"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check = StateGraph(AgentState)\n",
        "\n",
        "graph_with_helpfulness_check.add_node(\"agent\", call_model)\n",
        "graph_with_helpfulness_check.add_node(\"action\", tool_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ22o2mWVrfp"
      },
      "source": [
        "Lets set the `agent` node (`call_model`) as the **entrypoint** for our graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNWHwWxuRiLY",
        "outputId": "295f5a35-ceff-452a-ffb8-c52eada6a816"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x13b297bf0>"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check.set_entry_point(\"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsXeF6xlaXOZ"
      },
      "source": [
        "Next we define our **conditional logic** which will be used as a *conditional edge* withing our graph. The logic builds a simple chain that:\n",
        " 1. builds a prompt to determine the helpfulness of the LLM response using the 'initial query' and the 'final LLM response' as inputs;\n",
        " 2. builds a 'helpfulness check chain' that pass the helpfulness prompt to the check model and;\n",
        " 3. invoke the helpfulness check chain;\n",
        " 4. based on the check result, it determines if the flow should *end* or *continue*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "z_Sq3A9SaV1O"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def tool_call_or_helpful(state):\n",
        "  last_message = state[\"messages\"][-1]\n",
        "\n",
        "  if last_message.tool_calls:\n",
        "    return \"action\"\n",
        "\n",
        "  initial_query = state[\"messages\"][0]\n",
        "  final_response = state[\"messages\"][-1]\n",
        "\n",
        "  if len(state[\"messages\"]) > 10:\n",
        "    return \"END\"\n",
        "\n",
        "  prompt_template = \"\"\"\\\n",
        "  Given an initial query and a final response, determine if the final response is extremely helpful or not. \n",
        "  Consider if the final response is conclusive or if it is a partial answer or if it suggests that can have different meanings depending on the context or if it need more context. \n",
        "  If is not conclusive, then it is not helpful in this context.\n",
        "  Please indicate helpfulness with a 'Y' and unhelpfulness as an 'N'.\n",
        "\n",
        "  Initial Query:\n",
        "  {initial_query}\n",
        "\n",
        "  Final Response:\n",
        "  {final_response}\"\"\"\n",
        "\n",
        "  helpfullness_prompt_template = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "  helpfulness_check_model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
        "\n",
        "  helpfulness_chain = helpfullness_prompt_template | helpfulness_check_model | StrOutputParser()\n",
        "\n",
        "  helpfulness_response = helpfulness_chain.invoke({\"initial_query\" : initial_query.content, \"final_response\" : final_response.content})\n",
        "\n",
        "  if \"Y\" in helpfulness_response:\n",
        "    return \"end\"\n",
        "  else:\n",
        "    return \"continue\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BhnBW2YVsJO"
      },
      "source": [
        "Add the helpfullness conditional logic to the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVTKnWMbP_8T",
        "outputId": "7f729b1f-311c-4084-ceaf-0da437900c85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x13b297bf0>"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    tool_call_or_helpful,\n",
        "    {\n",
        "        \"continue\" : \"agent\",\n",
        "        \"action\" : \"action\",\n",
        "        \"end\" : END\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGDLEWOIVtK0"
      },
      "source": [
        "Connect the `action` back to `agent` node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbDK2MbuREgU",
        "outputId": "21a64c20-27a1-4e0e-afde-a639abaa8b55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x13b297bf0>"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check.add_edge(\"action\", \"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSI8AOaEVvT-"
      },
      "source": [
        "Compile out graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "oQldl8ERQ8lf"
      },
      "outputs": [],
      "source": [
        "agent_with_helpfulness_check = graph_with_helpfulness_check.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see how our graph looks like!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](./helpfulness-check-graph3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F67FGCMRVwGz"
      },
      "source": [
        "Give it a spin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3oo8E-PRK1T",
        "outputId": "f152dea8-96ad-4d29-d8b2-a064c96a8bd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='Deep Research Agents are advanced AI systems designed to assist with in-depth research tasks. They leverage deep learning techniques and large datasets to analyze complex information, generate insights, and support decision-making across various fields such as science, technology, medicine, and more. These agents can automate literature reviews, extract relevant data from vast sources, and provide comprehensive summaries, making research more efficient and thorough. Would you like me to find more detailed or specific information about Deep Research Agents?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 158, 'total_tokens': 251, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CKutZ7dcCD6G4jr5m4Mal9ouEBRCq', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--1c25d0c1-34ed-40a0-8db3-490f5f0cb866-0', usage_metadata={'input_tokens': 158, 'output_tokens': 93, 'total_tokens': 251, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"messages\" : [HumanMessage(content=\"What are Deep Research Agents?\")]}\n",
        "\n",
        "async for chunk in agent_with_helpfulness_check.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        print(values[\"messages\"])\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Langsmith trace\n",
        "\n",
        "The trace bellow show the first graph exectution. Notice the helpfulness check output (`Y`), which proves the LLM response is considered Helpful given our user Query (***\"What are Deep Research Agents?\"***)\n",
        "\n",
        "![](./langsmith-helpfulness-agent-trace.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Forcing a nonsesical prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='\"EV\" can have different meanings depending on the context. Could you please specify the context in which you encountered \"EV\"? For example, it could refer to \"Electric Vehicle,\" \"Expected Value\" in statistics, \"Enterprise Value\" in finance, or something else.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 158, 'total_tokens': 213, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CKvNmWCYLYTEC8SB7U8o5Zgf9DEFO', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--82f3954e-a6ad-44b7-9771-25b60afdab17-0', usage_metadata={'input_tokens': 158, 'output_tokens': 55, 'total_tokens': 213, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_y5pPQOD8GjT7oXpev2hunegA', 'function': {'arguments': '{\"query\":\"meaning of EV\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 216, 'total_tokens': 236, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CKvNop4FJhJemkZAcLckdqODI5cCs', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--2a78be1e-a2bf-4197-961d-88bb35092f71-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'meaning of EV'}, 'id': 'call_y5pPQOD8GjT7oXpev2hunegA', 'type': 'tool_call'}], usage_metadata={'input_tokens': 216, 'output_tokens': 20, 'total_tokens': 236, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "[ToolMessage(content='[{\"title\": \"What Is EV (Electric Vehicle)? - Eleport\", \"url\": \"https://eleport.com/what-is-ev-electric-vehicle/\", \"content\": \"The term ‚ÄúEV‚Äù stands for electric vehicle, which uses electric motors for propulsion instead of a petrol or diesel engine. If you‚Äôre searching for the EV meaning, it‚Äôs simple: an EV is any vehicle that runs fully or partially on electric power, typically using a rechargeable battery to drive an electric motor. In Europe, fully electric cars now make up over 17% of all car sales, with plug-in hybrids adding another 8.5%. [...] When someone says ‚Äúelectric car,‚Äù or ‚ÄúEV‚Äù they could mean a few different things. An EV, or electric vehicle, for most people is any vehicle that uses electricity for propulsion, but not all EVs are built the same. And some consider only purely battery-electric car an EV. So, what is an EV in terms of its types?\\\\n\\\\n#### Battery Electric Vehicles (BEVs) [...] To continue with infrastructure, what is EV charging? At first glance, charging an electric vehicle (EV)‚Äîa car powered entirely or partially by electricity instead of petrol‚Äîmight seem like the biggest change for new drivers‚Äîand in some ways, it is.\", \"score\": 0.87782305}, {\"title\": \"Electric Vehicle (EV) Definition - Alternative Fuels Data Center\", \"url\": \"https://afdc.energy.gov/laws/12660\", \"content\": \"An EV is defined as a vehicle that can be powered by an electric motor that draws electricity from a battery and is capable of being charged from an external source. An EV includes both a vehicle that can only be powered by an electric motor that draws electricity from a battery (EV) and a vehicle that can be powered by an electric motor that draws electricity from a battery and by an internal combustion engine (plug-in hybrid electric vehicle). [...] Open Gov\\\\n   Accessibility\\\\n   Privacy\\\\n   Information Quality\\\\n   Web Policies\\\\n   Vulnerability Disclosure Program\\\\n   Whistleblower Protection [...] Maps & Data\\\\n       Case Studies\\\\n       Publications\\\\n       Tools\\\\n\\\\n   Maps & Data\\\\n   Case Studies\\\\n   Publications\\\\n   Tools\\\\n\\\\n1.   AFDC\\\\n2.   Laws & Incentives\\\\n3.   State\\\\n\\\\n More in this section \\\\n\\\\n   Search\\\\n   Federal\\\\n   State\\\\n   Local Examples\\\\n   Utility Programs\\\\n   Summary Tables\\\\n\\\\nElectric Vehicle (EV) Definition\", \"score\": 0.85008353}, {\"title\": \"EV - Definition by AcronymFinder\", \"url\": \"https://www.acronymfinder.com/EV.html\", \"content\": \"| Rank Abbr. | Meaning |  |\\\\n --- \\\\n| EV.html \\\\\"EV - Extended Validation\\\\\") | Extended Validation | Image 1 |\\\\n| EV.html \\\\\"EV - Electric Vehicle\\\\\") | Electric Vehicle | Image 2 |\\\\n| EV.html \\\\\"EV - Electro Voice\\\\\") | Electro Voice | Image 3 |\\\\n| \\\\n |\\\\n| EV-(EV).html \\\\\"EV - Eingetragener Verein (German: Registered Association)\\\\\") | Eingetragener Verein (German: Registered Association) | Image 4 |\\\\n| EV.html \\\\\"EV - Electron Volt\\\\\") | Electron Volt | Image 5 | [...] | EV-(EV).html \\\\\"EV - EudraVigilance (data processing network; European Medicines Agency)\\\\\") | EudraVigilance (data processing network; European Medicines Agency) | Image 28 |\\\\n| EV.html \\\\\"EV - Ebola virus\\\\\") | Ebola virus | Image 29 |\\\\n| EV.html \\\\\"EV - Extreme Value\\\\\") | Extreme Value | Image 30 |\\\\n| EV.html \\\\\"EV - Exhaust Valve\\\\\") | Exhaust Valve | Image 31 |\\\\n| EV-(EV).html \\\\\"EV - Exposed Variable (plumbing)\\\\\") | Exposed Variable (plumbing) | Image 32 | [...] | EV-(EV).html \\\\\"EV - Enter Vehicle (police incident code)\\\\\") | Enter Vehicle (police incident code) | Image 18 |\\\\n| EV-(EV).html \\\\\"EV - Environment Variable (computing)\\\\\") | Environment Variable (computing) | Image 19 |\\\\n| EV-(EV).html \\\\\"EV - Esophageal Varices (medical disorder)\\\\\") | Esophageal Varices (medical disorder) | Image 20 |\\\\n| EV-(EV).html \\\\\"EV - Escape Velocity (computer game)\\\\\") | Escape Velocity (computer game) | Image 21 |\\\\n| EV.html \\\\\"EV - Embedded Value\\\\\") | Embedded Value | Image 22 |\", \"score\": 0.8430832}, {\"title\": \"EV Meaning (Electric Vehicle) ‚Äì A Detailed Guide - Karsan\", \"url\": \"https://www.karsan.com/en/blog/technology-blog/ev-meaning-electric-vehicle-a-detailed-guide\", \"content\": \"Electric cars aren‚Äôt just a concept for tomorrow‚Äîthey‚Äôre already on the roads today, changing the way we move and shaping the cities we live in. You‚Äôve probably heard the term EV everywhere lately, but what exactly does it mean, how does it work, and why is it seen as the future of driving?\\\\n\\\\n## What Does EV Mean?\\\\n\\\\nEV stands for Electric Vehicle‚Äîa broad term for any vehicle powered by electricity rather than a conventional internal combustion engine. [...] BEV (Battery Electric Vehicle) ‚Äì Fully electric. Runs only on battery power. Must be charged from an external source, like a home wallbox or public charging station.\\\\n PHEV (Plug-in Hybrid Electric Vehicle) ‚Äì Combines a petrol engine with a larger battery that can be plugged in. Can run short trips on electric power alone, with petrol as backup for longer journeys. [...] HEV (Hybrid Electric Vehicle) ‚Äì Petrol engine plus electric motor, but no plug-in charging. Charges itself via regenerative braking and the engine. Each type offers a different mix of electric driving range, convenience, and infrastructure needs.\", \"score\": 0.8138313}, {\"title\": \"What Is an Electric Vehicle and How Does It Work? - Constellation\", \"url\": \"https://www.constellation.com/energy-101/energy-innovation/what-is-an-electric-vehicle.html\", \"content\": \"EV is an acronym for electric vehicle. What are EVs? They are cars with an electric motor powered by a battery instead of a combustion engine powered by gasoline.\", \"score\": 0.7876867}]', name='tavily_search_results_json', id='8d592122-086f-48bc-895f-65bcde6da526', tool_call_id='call_y5pPQOD8GjT7oXpev2hunegA', artifact={'query': 'meaning of EV', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://eleport.com/what-is-ev-electric-vehicle/', 'title': 'What Is EV (Electric Vehicle)? - Eleport', 'content': 'The term ‚ÄúEV‚Äù stands for electric vehicle, which uses electric motors for propulsion instead of a petrol or diesel engine. If you‚Äôre searching for the EV meaning, it‚Äôs simple: an EV is any vehicle that runs fully or partially on electric power, typically using a rechargeable battery to drive an electric motor. In Europe, fully electric cars now make up over 17% of all car sales, with plug-in hybrids adding another 8.5%. [...] When someone says ‚Äúelectric car,‚Äù or ‚ÄúEV‚Äù they could mean a few different things. An EV, or electric vehicle, for most people is any vehicle that uses electricity for propulsion, but not all EVs are built the same. And some consider only purely battery-electric car an EV. So, what is an EV in terms of its types?\\n\\n#### Battery Electric Vehicles (BEVs) [...] To continue with infrastructure, what is EV charging? At first glance, charging an electric vehicle (EV)‚Äîa car powered entirely or partially by electricity instead of petrol‚Äîmight seem like the biggest change for new drivers‚Äîand in some ways, it is.', 'score': 0.87782305, 'raw_content': None}, {'url': 'https://afdc.energy.gov/laws/12660', 'title': 'Electric Vehicle (EV) Definition - Alternative Fuels Data Center', 'content': 'An EV is defined as a vehicle that can be powered by an electric motor that draws electricity from a battery and is capable of being charged from an external source. An EV includes both a vehicle that can only be powered by an electric motor that draws electricity from a battery (EV) and a vehicle that can be powered by an electric motor that draws electricity from a battery and by an internal combustion engine (plug-in hybrid electric vehicle). [...] Open Gov\\n   Accessibility\\n   Privacy\\n   Information Quality\\n   Web Policies\\n   Vulnerability Disclosure Program\\n   Whistleblower Protection [...] Maps & Data\\n       Case Studies\\n       Publications\\n       Tools\\n\\n   Maps & Data\\n   Case Studies\\n   Publications\\n   Tools\\n\\n1.   AFDC\\n2.   Laws & Incentives\\n3.   State\\n\\n More in this section \\n\\n   Search\\n   Federal\\n   State\\n   Local Examples\\n   Utility Programs\\n   Summary Tables\\n\\nElectric Vehicle (EV) Definition', 'score': 0.85008353, 'raw_content': None}, {'url': 'https://www.acronymfinder.com/EV.html', 'title': 'EV - Definition by AcronymFinder', 'content': '| Rank Abbr. | Meaning |  |\\n --- \\n| EV.html \"EV - Extended Validation\") | Extended Validation | Image 1 |\\n| EV.html \"EV - Electric Vehicle\") | Electric Vehicle | Image 2 |\\n| EV.html \"EV - Electro Voice\") | Electro Voice | Image 3 |\\n| \\n |\\n| EV-(EV).html \"EV - Eingetragener Verein (German: Registered Association)\") | Eingetragener Verein (German: Registered Association) | Image 4 |\\n| EV.html \"EV - Electron Volt\") | Electron Volt | Image 5 | [...] | EV-(EV).html \"EV - EudraVigilance (data processing network; European Medicines Agency)\") | EudraVigilance (data processing network; European Medicines Agency) | Image 28 |\\n| EV.html \"EV - Ebola virus\") | Ebola virus | Image 29 |\\n| EV.html \"EV - Extreme Value\") | Extreme Value | Image 30 |\\n| EV.html \"EV - Exhaust Valve\") | Exhaust Valve | Image 31 |\\n| EV-(EV).html \"EV - Exposed Variable (plumbing)\") | Exposed Variable (plumbing) | Image 32 | [...] | EV-(EV).html \"EV - Enter Vehicle (police incident code)\") | Enter Vehicle (police incident code) | Image 18 |\\n| EV-(EV).html \"EV - Environment Variable (computing)\") | Environment Variable (computing) | Image 19 |\\n| EV-(EV).html \"EV - Esophageal Varices (medical disorder)\") | Esophageal Varices (medical disorder) | Image 20 |\\n| EV-(EV).html \"EV - Escape Velocity (computer game)\") | Escape Velocity (computer game) | Image 21 |\\n| EV.html \"EV - Embedded Value\") | Embedded Value | Image 22 |', 'score': 0.8430832, 'raw_content': None}, {'url': 'https://www.karsan.com/en/blog/technology-blog/ev-meaning-electric-vehicle-a-detailed-guide', 'title': 'EV Meaning (Electric Vehicle) ‚Äì A Detailed Guide - Karsan', 'content': 'Electric cars aren‚Äôt just a concept for tomorrow‚Äîthey‚Äôre already on the roads today, changing the way we move and shaping the cities we live in. You‚Äôve probably heard the term EV everywhere lately, but what exactly does it mean, how does it work, and why is it seen as the future of driving?\\n\\n## What Does EV Mean?\\n\\nEV stands for Electric Vehicle‚Äîa broad term for any vehicle powered by electricity rather than a conventional internal combustion engine. [...] BEV (Battery Electric Vehicle) ‚Äì Fully electric. Runs only on battery power. Must be charged from an external source, like a home wallbox or public charging station.\\n PHEV (Plug-in Hybrid Electric Vehicle) ‚Äì Combines a petrol engine with a larger battery that can be plugged in. Can run short trips on electric power alone, with petrol as backup for longer journeys. [...] HEV (Hybrid Electric Vehicle) ‚Äì Petrol engine plus electric motor, but no plug-in charging. Charges itself via regenerative braking and the engine. Each type offers a different mix of electric driving range, convenience, and infrastructure needs.', 'score': 0.8138313, 'raw_content': None}, {'url': 'https://www.constellation.com/energy-101/energy-innovation/what-is-an-electric-vehicle.html', 'title': 'What Is an Electric Vehicle and How Does It Work? - Constellation', 'content': 'EV is an acronym for electric vehicle. What are EVs? They are cars with an electric motor powered by a battery instead of a combustion engine powered by gasoline.', 'score': 0.7876867, 'raw_content': None}], 'response_time': 1.47, 'request_id': '1d2f7a4f-4203-4a73-a40b-a79b90e2f9b7'})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='\"EV\" stands for \"Electric Vehicle.\" It refers to any vehicle that is powered by an electric motor using electricity stored in a rechargeable battery, rather than using a traditional internal combustion engine fueled by petrol or diesel. There are different types of EVs, including fully electric vehicles (BEVs), plug-in hybrid electric vehicles (PHEVs), and hybrid electric vehicles (HEVs).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 1592, 'total_tokens': 1670, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CKvNq6xKqUoWKEzHHehlD1vbktSQH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--aca984ab-28ab-4923-884f-5671365ec17f-0', usage_metadata={'input_tokens': 1592, 'output_tokens': 78, 'total_tokens': 1670, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"messages\" : [HumanMessage(content=\"What is the meaning of ev\")]}\n",
        "\n",
        "async for chunk in agent_with_helpfulness_check.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        print(values[\"messages\"])\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Langsmith trace\n",
        "\n",
        "The trace bellow show the second graph exectution using a query more vague. Notice the helpfulness check output (`N`) indicates the first LLM response is NOT considered Helpful given our user Query (***\"What is the meaning of ev\"***) forcing our agent to continue calling the LLM.\n",
        "\n",
        "![](./langsmith-helpfulness-agent-2nd-trace.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVmZPs6lnpsM"
      },
      "source": [
        "## Part 3: LangGraph for the \"Patterns\" of GenAI\n",
        "\n",
        "### Task 4: Helpfulness Check of Gen AI Pattern Descriptions\n",
        "\n",
        "Let's ask our system about the 3 main patterns in Generative AI:\n",
        "\n",
        "1. Context Engineering\n",
        "2. Fine-tuning\n",
        "3. Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "ZoLl7GlXoae-"
      },
      "outputs": [],
      "source": [
        "patterns = [\"Context Engineering\", \"Fine-tuning\", \"LLM-based agents\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zkh0YJuCp3Zl",
        "outputId": "d847426e-71b3-47e6-b1ae-351a78d68d1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the search results, Context Engineering is an emerging discipline within AI that involves designing and managing the environment, information flow, and tools that an AI system interacts with to perform its tasks effectively. It goes beyond simple prompt engineering by focusing on creating dynamic, context-aware systems that provide the right information, instructions, and resources to AI models, especially large language models (LLMs), to improve their performance, reliability, and relevance.\n",
            "\n",
            "The concept gained traction in the early to mid-2020s, particularly around 2025, as AI applications evolved from static prompts to complex, dynamic, agentic systems. Notable figures like Tobi Lutke and Dex Horthy have contributed to popularizing the term, emphasizing its importance in building more sophisticated and reliable AI systems.\n",
            "\n",
            "Would you like a more detailed history or specific examples of its application?\n",
            "\n",
            "\n",
            "\n",
            "Fine-tuning is a machine learning technique used to adapt a pre-trained model to a specific task or dataset. Instead of training a model from scratch, which can be resource-intensive and time-consuming, fine-tuning involves taking an existing model that has already learned general features from a large dataset and then further training it on a smaller, task-specific dataset. This process helps the model specialize in the new task while leveraging the knowledge it has already acquired.\n",
            "\n",
            "Fine-tuning has become a prominent approach in the development of large language models and other deep learning models, enabling them to perform well on specialized tasks such as medical diagnosis, legal analysis, or customer service.\n",
            "\n",
            "As for when it \"broke onto the scene,\" fine-tuning has been around for quite some time, but it gained widespread popularity and recognition with the rise of transfer learning in deep neural networks, particularly in natural language processing (NLP) and computer vision. The advent of models like BERT (introduced by Google in 2018) and GPT (by OpenAI) significantly propelled the use of fine-tuning, as these models could be pre-trained on massive datasets and then fine-tuned for specific applications. This shift marked a major milestone in AI development, making fine-tuning a standard practice in the field.\n",
            "\n",
            "Would you like me to find more detailed historical information or specific milestones related to fine-tuning?\n",
            "\n",
            "\n",
            "\n",
            "LLM-based agents are intelligent systems that utilize large language models (LLMs) to perform a variety of tasks, such as understanding natural language, generating human-like text, and making decisions or taking actions based on the input they receive. These agents leverage the capabilities of LLMs like GPT-3, GPT-4, and similar models to interact with users, automate processes, and solve complex problems across different domains.\n",
            "\n",
            "The concept of LLM-based agents started gaining significant attention around 2020-2021, as large language models became more powerful and accessible. The release of OpenAI's GPT-3 in June 2020 marked a major milestone, showcasing the potential of LLMs to serve as foundational components for building intelligent agents. Since then, the development and deployment of LLM-based agents have rapidly expanded, becoming a prominent area of research and application in artificial intelligence.\n",
            "\n",
            "Would you like more detailed information on the history, specific applications, or recent advancements in LLM-based agents?\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for pattern in patterns:\n",
        "  what_is_string = f\"What is {pattern} and when did it break onto the scene??\"\n",
        "  inputs = {\"messages\" : [HumanMessage(content=what_is_string)]}\n",
        "  messages = agent_with_helpfulness_check.invoke(inputs)\n",
        "  print(messages[\"messages\"][-1].content)\n",
        "  print(\"\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
