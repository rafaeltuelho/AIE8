{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCk2Rx4cjlYF"
      },
      "source": [
        "# Synthetic Data Generation Using RAGAS - RAG Evaluation with LangSmith\n",
        "\n",
        "In the following notebook we'll explore a use-case for RAGAS' synthetic testset generation workflow!\n",
        "\n",
        "\n",
        "\n",
        "- ðŸ¤ BREAKOUT ROOM #1\n",
        "  1. Use RAGAS to Generate Synthetic Data\n",
        "\n",
        "- ðŸ¤ BREAKOUT ROOM #2\n",
        "  1. Load them into a LangSmith Dataset\n",
        "  2. Evaluate our RAG chain against the synthetic test data\n",
        "  3. Make changes to our pipeline\n",
        "  4. Evaluate the modified pipeline\n",
        "\n",
        "SDG is a critical piece of the puzzle, especially for early iteration! Without it, it would not be nearly as easy to get high quality early signal for our application's performance.\n",
        "\n",
        "Let's dive in!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bG2ta-B478G"
      },
      "source": [
        "# ðŸ¤ BREAKOUT ROOM #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VUI7vF_kbv9"
      },
      "source": [
        "## Task 1: Dependencies and API Keys\n",
        "\n",
        "We'll need to install a number of API keys and dependencies, since we'll be leveraging a number of great technologies for this pipeline!\n",
        "\n",
        "1. OpenAI's endpoints to handle the Synthetic Data Generation\n",
        "2. OpenAI's Endpoints for our RAG pipeline and LangSmith evaluation\n",
        "3. QDrant as our vectorstore\n",
        "4. LangSmith for our evaluation coordinator!\n",
        "\n",
        "Let's install and provide all the required information below!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dependencies and API Keys:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### NLTK Import\n",
        "\n",
        "To prevent errors that may occur based on OS - we'll import NLTK and download the needed packages to ensure correct handling of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/rsoares/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/rsoares/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll also want to set a project name to make things easier for ourselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIM - SDG - {uuid4().hex[0:8]}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OpenAI's API Key!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generating Synthetic Test Data\n",
        "\n",
        "We wil be using Ragas to build out a set of synthetic test questions, references, and reference contexts. This is useful because it will allow us to find out how our system is performing.\n",
        "\n",
        "> NOTE: Ragas is best suited for finding *directional* changes in your LLM-based systems. The absolute scores aren't comparable in a vacuum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Preparation\n",
        "\n",
        "We'll prepare our data - which should hopefull be familiar at this point since it's our Use-Case Data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, let's load our data into a familiar LangChain format using the `DirectoryLoader`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "path = \"data/\"\n",
        "loader = DirectoryLoader(path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of documents (PDF pages): 64\n",
            "\n",
            "Document 1 page_content:\n",
            "NBER WORKING PAPER SERIES\n",
            "HOW PEOPLE USE CHATGPT\n",
            "Aaron Chatterji\n",
            "Thomas Cunningham\n",
            "David J. Deming\n",
            "Zoe Hitzig\n",
            "Christopher Ong\n",
            "Carl Yan Shan\n",
            "Kevin Wadman\n",
            "Working Paper 34255\n",
            "http://www.nber.org/papers/w34255\n",
            "NATIONAL BUREAU OF ECONOMIC RESEARCH\n",
            "1050 Massachusetts Avenue\n",
            "Cambridge, MA 02138\n",
            "September 2025\n",
            "We acknowledge help and comments from Joshua Achiam, Hemanth Asirvatham, Ryan \n",
            "Beiermeister, Rachel Brown, Cassandra Duchan Solis, Jason Kwon, Elliott Mokski, Kevin Rao, \n",
            "Harrison Satcher, Gawesha Weeratunga, Hannah Wong, and Analytics & Insights team. We \n",
            "especially thank Tyna Eloundou and Pamela Mishkin who in several ways laid the foundation for \n",
            "this work. This study was approved by Harvard IRB (IRB25-0983). A repository containing all \n",
            "code run to produce the analyses in this paper is available on request. The views expressed herein \n",
            "are those of the authors and do not necessarily reflect the views of the National Bureau of \n",
            "Economic Research.\n",
            "At least one co-author has disclosed additional relationships of potential relevance for this research. \n",
            "Further information is available online at http://www.nber.org/papers/w34255\n",
            "NBER working papers are circulated for discussion and comment purposes. They have not been \n",
            "peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies \n",
            "official NBER publications.\n",
            "Â© 2025 by Aaron Chatterji, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, \n",
            "Carl Yan Shan, and Kevin Wadman. All rights reserved. Short sections of text, not to exceed two \n",
            "paragraphs, may be quoted without explicit permission provided that full credit, including Â© \n",
            "notice, is given to the source.\n",
            "\n",
            "Document 2 page_content:\n",
            "How People Use ChatGPT\n",
            "Aaron Chatterji, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl\n",
            "Yan Shan, and Kevin Wadman\n",
            "NBER Working Paper No. 34255\n",
            "September 2025\n",
            "JEL No. J01, O3, O4\n",
            "ABSTRACT\n",
            "Despite the rapid adoption of LLM chatbots, little is known about how they are used. We \n",
            "document the growth of ChatGPTâ€™s consumer product from its launch in November 2022 \n",
            "through July 2025, when it had been adopted by around 10% of the worldâ€™s adult population. \n",
            "Early adopters were disproportionately male but the gender gap has narrowed dramatically, and \n",
            "we find higher growth rates in lower-income countries. Using a privacy-preserving automated \n",
            "pipeline, we classify usage patterns within a representative sample of ChatGPT conversations. \n",
            "We find steady growth in work-related messages but even faster growth in non-work-related \n",
            "messages, which have grown from 53% to more than 70% of all usage. Work usage is more \n",
            "common for educated users in highly-paid professional occupations. We classify messages by \n",
            "conversation topic and find that â€œPractical Guidance,â€ â€œSeeking Information,â€ and â€œWritingâ€ are \n",
            "the three most common topics and collectively account for nearly 80% of all conversations. \n",
            "Writing dominates work-related tasks, highlighting chatbotsâ€™ unique ability to generate digital \n",
            "outputs compared to traditional search engines. Computer programming and self-expression both \n",
            "represent relatively small shares of use. Overall, we find that ChatGPT provides economic value \n",
            "through decision support, which is especially important in knowledge-intensive jobs.\n",
            "Aaron Chatterji\n",
            "Duke University\n",
            "Fuqua School of Business \n",
            "and OpenAI\n",
            "ronnie@duke.edu\n",
            "Thomas Cunningham \n",
            "OpenAI\n",
            "tom.cunningham@gmail.com\n",
            "David J. Deming\n",
            "Harvard University\n",
            "Harvard Kennedy School \n",
            "and NBER\n",
            "david_deming@harvard.edu\n",
            "Zoe Hitzig\n",
            "OpenAI\n",
            "and Harvard Society of Fellows\n",
            "zhitzig@g.harvard.edu\n",
            "Christopher Ong\n",
            "Harvard University\n",
            "and OpenAI\n",
            "christopherong@hks.harvard.edu\n",
            "Carl Yan Shan\n",
            "OpenAI\n",
            "cshan@openai.com\n",
            "Kevin Wadman\n",
            "OpenAI\n",
            "kevin.wadman@c-openai.com\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of documents (PDF pages): {len(docs)}\\n\")\n",
        "for i, doc in enumerate(docs[:2]):\n",
        "    print(f\"Document {i+1} page_content:\\n{doc.page_content}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Knowledge Graph Based Synthetic Generation\n",
        "\n",
        "Ragas uses a knowledge graph based approach to create data. This is extremely useful as it allows us to create complex queries rather simply. The additional testset complexity allows us to evaluate larger problems more effectively, as systems tend to be very strong on simple evaluation tasks.\n",
        "\n",
        "Let's start by defining our `generator_llm` (which will generate our questions, summaries, and more), and our `generator_embeddings` which will be useful in building our graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unrolled SDG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we're going to instantiate our Knowledge Graph.\n",
        "\n",
        "This graph will contain N number of nodes that have M number of relationships. These nodes and relationships (AKA \"edges\") will define our knowledge graph and be used later to construct relevant questions and responses.\n",
        "\n",
        "![RAGAS Knowledge Graph diagram](https://docs.ragas.io/en/stable/_static/imgs/kg_rag.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 0, relationships: 0)"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.graph import KnowledgeGraph\n",
        "\n",
        "kg = KnowledgeGraph()\n",
        "kg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first step we're going to take is to simply insert each of our full documents into the graph. This will provide a base that we can apply transformations to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 64, relationships: 0)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.graph import Node, NodeType\n",
        "\n",
        "### NOTICE: We're using a subset of the data for this example - this is to keep costs/time down.\n",
        "for doc in docs:\n",
        "    kg.nodes.append(\n",
        "        Node(\n",
        "            type=NodeType.DOCUMENT,\n",
        "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
        "        )\n",
        "    )\n",
        "kg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we'll apply the *default* transformations to our knowledge graph. This will take the nodes currently on the graph and transform them based on a set of [default transformations](https://docs.ragas.io/en/latest/references/transforms/#ragas.testset.transforms.default_transforms).\n",
        "\n",
        "These default transformations are dependent on the corpus length, in our case:\n",
        "\n",
        "- Producing Summaries -> produces summaries of the documents\n",
        "- Extracting Headlines -> finding the overall headline for the document\n",
        "- Theme Extractor -> extracts broad themes about the documents\n",
        "\n",
        "**It then uses cosine-similarity and heuristics between the embeddings of the above transformations to construct relationships between the nodes.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d523fa69b0354acf81b8e3755f848eb8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlinesExtractor:   0%|          | 0/21 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1fc85b358954b1cb87b5b29e7bd6290",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlineSplitter:   0%|          | 0/64 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51f09c5ba78048b3b58116612719b731",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/38 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Property 'summary' already exists in node '5d6be7'. Skipping!\n",
            "Property 'summary' already exists in node 'b1cfc3'. Skipping!\n",
            "Property 'summary' already exists in node 'a7443a'. Skipping!\n",
            "Property 'summary' already exists in node 'b42e24'. Skipping!\n",
            "Property 'summary' already exists in node '5ead91'. Skipping!\n",
            "Property 'summary' already exists in node '237242'. Skipping!\n",
            "Property 'summary' already exists in node 'd7812e'. Skipping!\n",
            "Property 'summary' already exists in node '2808eb'. Skipping!\n",
            "Property 'summary' already exists in node '99e090'. Skipping!\n",
            "Property 'summary' already exists in node '983599'. Skipping!\n",
            "Property 'summary' already exists in node '7f645e'. Skipping!\n",
            "Property 'summary' already exists in node 'ba9ff9'. Skipping!\n",
            "Property 'summary' already exists in node '4b116f'. Skipping!\n",
            "Property 'summary' already exists in node 'e202a0'. Skipping!\n",
            "Property 'summary' already exists in node '5073b2'. Skipping!\n",
            "Property 'summary' already exists in node 'd5c8d0'. Skipping!\n",
            "Property 'summary' already exists in node 'f1bf94'. Skipping!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1015102715c945c588918b01f98bb248",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8df0f9cb7904648ad62f774ff52e884",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/48 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Property 'summary_embedding' already exists in node 'ba9ff9'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '237242'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'a7443a'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '99e090'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '2808eb'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'b42e24'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '5ead91'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'd7812e'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '7f645e'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '5d6be7'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'b1cfc3'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '983599'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '4b116f'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'e202a0'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '5073b2'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'd5c8d0'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'f1bf94'. Skipping!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5bff8f5d09574191a6fb91205626396d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 86, relationships: 712)"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.transforms import default_transforms, apply_transforms\n",
        "\n",
        "transformer_llm = generator_llm\n",
        "embedding_model = generator_embeddings\n",
        "\n",
        "default_transforms = default_transforms(documents=docs, llm=transformer_llm, embedding_model=embedding_model)\n",
        "apply_transforms(kg, default_transforms)\n",
        "kg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can save and load our knowledge graphs as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 86, relationships: 712)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kg.save(\"usecase_data_kg.json\")\n",
        "usecase_data_kg = KnowledgeGraph.load(\"usecase_data_kg.json\")\n",
        "usecase_data_kg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using our knowledge graph, we can construct a \"test set generator\" - which will allow us to create queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=embedding_model, knowledge_graph=usecase_data_kg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, we'd like to be able to define the kinds of queries we're generating - which is made simple by Ragas having pre-created a number of different \"QuerySynthesizer\"s.\n",
        "\n",
        "Each of these Synthetsizers is going to tackle a separate kind of query which will be generated from a scenario and a persona.\n",
        "\n",
        "**In essence, Ragas will use an LLM to generate a persona of someone who would interact with the data** - and then use a scenario to construct a question from that data and persona."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.testset.synthesizers import default_query_distribution, SingleHopSpecificQuerySynthesizer, MultiHopAbstractQuerySynthesizer, MultiHopSpecificQuerySynthesizer\n",
        "\n",
        "query_distribution = [\n",
        "        (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.5),\n",
        "        (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.25),\n",
        "        (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.25),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### â“ Question #1:\n",
        "\n",
        "What are the three types of query synthesizers doing? Describe each one in simple terms.\n",
        "\n",
        "##### âœ… Answear:\n",
        "They represent diffenrent types of questions a user can use while interactiong with a RAG system.\n",
        "\n",
        " * **SingleHop** queries represent a fact-based question that can be answered with a single retrieval from a document source.\n",
        " * **MultiHop** queries involves multiple steps of reasoning, requiring information from two or more sources. \n",
        " * **Specific** queries focuses on clear, fact-based retrieval. The goal in RAG is to retrieve highly relevant information from one or more documents that directly address the specific question.\n",
        " * **Abstract** queries requires a broader, more interpretive response. In RAG, abstract queries challenge the retrieval system to pull from documents that contain higher-level reasoning, explanations, or opinions, rather than simple facts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we can use our `TestSetGenerator` to generate our testset!\n",
        "\n",
        "The diagram below is a representation of a RAGAS Testset:\n",
        "\n",
        "![](https://docs.ragas.io/en/stable/_static/imgs/scenario_rag.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fddd5db3bc954d4690b1ebccf4820775",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "661c4337b98746289a883aa6b7d28030",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91976967d4044c21823000062d759341",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What does July 2025 mean for ChatGPT users?</td>\n",
              "      <td>[Introduction ChatGPT launched in November 202...</td>\n",
              "      <td>By July 2025, 18 billion messages were being s...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is Handa et al. (2025) about in relation ...</td>\n",
              "      <td>[Table 1: ChatGPT daily message counts (millio...</td>\n",
              "      <td>Handa et al. (2025) report on ChatGPT daily me...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Section what does it mean in the context of Ch...</td>\n",
              "      <td>[Variation by Occupation Figure 23 presents va...</td>\n",
              "      <td>The context discusses variation in ChatGPT usa...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>July 2025 use ChatGPT how many</td>\n",
              "      <td>[Conclusion This paper studies the rapid growt...</td>\n",
              "      <td>By July 2025, ChatGPT had been used weekly by ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how chatgpt use differ by occupation and priva...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nTable 1: ChatGPT daily message cou...</td>\n",
              "      <td>The context shows that ChatGPT usage varies si...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ChatGPT use vs other AI like Claude impact wor...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nTable 1: ChatGPT daily message cou...</td>\n",
              "      <td>The context shows ChatGPT mostly used for prac...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does the regression analysis of occupation...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nVariation by Occupation Figure 23 ...</td>\n",
              "      <td>The regression analysis of occupation effects,...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Based on the rapid growth of ChatGPT usage in ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
              "      <td>The rapid growth of ChatGPT in the US, with mo...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How has the usage of ChatGPT evolved by July 2...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nIntroduction ChatGPT launched in N...</td>\n",
              "      <td>By July 2025, ChatGPT experienced rapid growth...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Hwo do Handa et al., 2025, describe the differ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nIntroduction ChatGPT launched in N...</td>\n",
              "      <td>Handa et al., 2025, report that while most Cha...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          user_input  \\\n",
              "0        What does July 2025 mean for ChatGPT users?   \n",
              "1  What is Handa et al. (2025) about in relation ...   \n",
              "2  Section what does it mean in the context of Ch...   \n",
              "3                     July 2025 use ChatGPT how many   \n",
              "4  how chatgpt use differ by occupation and priva...   \n",
              "5  ChatGPT use vs other AI like Claude impact wor...   \n",
              "6  How does the regression analysis of occupation...   \n",
              "7  Based on the rapid growth of ChatGPT usage in ...   \n",
              "8  How has the usage of ChatGPT evolved by July 2...   \n",
              "9  Hwo do Handa et al., 2025, describe the differ...   \n",
              "\n",
              "                                  reference_contexts  \\\n",
              "0  [Introduction ChatGPT launched in November 202...   \n",
              "1  [Table 1: ChatGPT daily message counts (millio...   \n",
              "2  [Variation by Occupation Figure 23 presents va...   \n",
              "3  [Conclusion This paper studies the rapid growt...   \n",
              "4  [<1-hop>\\n\\nTable 1: ChatGPT daily message cou...   \n",
              "5  [<1-hop>\\n\\nTable 1: ChatGPT daily message cou...   \n",
              "6  [<1-hop>\\n\\nVariation by Occupation Figure 23 ...   \n",
              "7  [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
              "8  [<1-hop>\\n\\nIntroduction ChatGPT launched in N...   \n",
              "9  [<1-hop>\\n\\nIntroduction ChatGPT launched in N...   \n",
              "\n",
              "                                           reference  \\\n",
              "0  By July 2025, 18 billion messages were being s...   \n",
              "1  Handa et al. (2025) report on ChatGPT daily me...   \n",
              "2  The context discusses variation in ChatGPT usa...   \n",
              "3  By July 2025, ChatGPT had been used weekly by ...   \n",
              "4  The context shows that ChatGPT usage varies si...   \n",
              "5  The context shows ChatGPT mostly used for prac...   \n",
              "6  The regression analysis of occupation effects,...   \n",
              "7  The rapid growth of ChatGPT in the US, with mo...   \n",
              "8  By July 2025, ChatGPT experienced rapid growth...   \n",
              "9  Handa et al., 2025, report that while most Cha...   \n",
              "\n",
              "                       synthesizer_name  \n",
              "0  single_hop_specifc_query_synthesizer  \n",
              "1  single_hop_specifc_query_synthesizer  \n",
              "2  single_hop_specifc_query_synthesizer  \n",
              "3  single_hop_specifc_query_synthesizer  \n",
              "4  multi_hop_abstract_query_synthesizer  \n",
              "5  multi_hop_abstract_query_synthesizer  \n",
              "6  multi_hop_abstract_query_synthesizer  \n",
              "7  multi_hop_specific_query_synthesizer  \n",
              "8  multi_hop_specific_query_synthesizer  \n",
              "9  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testset = generator.generate(testset_size=10, query_distribution=query_distribution)\n",
        "testset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Abstracted SDG\n",
        "\n",
        "The above method is the full process - but we can shortcut that using the provided abstractions!\n",
        "\n",
        "This will generate our knowledge graph under the hood, and will - from there - generate our personas and scenarios to construct our queries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2771ec989e384fb2bbbb7633edd76885",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlinesExtractor:   0%|          | 0/21 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d85b6a2f7d04ba5bfcd188910176270",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlineSplitter:   0%|          | 0/64 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa2cb276990e42a092612e7cfc557a6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/38 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Property 'summary' already exists in node 'bdb275'. Skipping!\n",
            "Property 'summary' already exists in node '70ec49'. Skipping!\n",
            "Property 'summary' already exists in node 'a12b37'. Skipping!\n",
            "Property 'summary' already exists in node '3e580d'. Skipping!\n",
            "Property 'summary' already exists in node '5012b3'. Skipping!\n",
            "Property 'summary' already exists in node '09b909'. Skipping!\n",
            "Property 'summary' already exists in node '73c399'. Skipping!\n",
            "Property 'summary' already exists in node '4c6efd'. Skipping!\n",
            "Property 'summary' already exists in node 'fe9738'. Skipping!\n",
            "Property 'summary' already exists in node 'f1ed55'. Skipping!\n",
            "Property 'summary' already exists in node '1262c2'. Skipping!\n",
            "Property 'summary' already exists in node '34e7d1'. Skipping!\n",
            "Property 'summary' already exists in node '2c169a'. Skipping!\n",
            "Property 'summary' already exists in node '7b5c6f'. Skipping!\n",
            "Property 'summary' already exists in node '0471b2'. Skipping!\n",
            "Property 'summary' already exists in node '74895b'. Skipping!\n",
            "Property 'summary' already exists in node '78472e'. Skipping!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad4623892dd04180ae5aa2cb0b0b6505",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab6325912a354608af127aabeaee6c22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/48 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Property 'summary_embedding' already exists in node 'fe9738'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '4c6efd'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'bdb275'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '73c399'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '09b909'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'a12b37'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '1262c2'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '5012b3'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'f1ed55'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '3e580d'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '70ec49'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '34e7d1'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '0471b2'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '78472e'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '7b5c6f'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '74895b'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '2c169a'. Skipping!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac89cfc1990446dda9180052f611abd1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75d720fddc40444883d4be4247e740ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31a21905b0714ec49f1943465fc266db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74da3db6b55e4984987f775df02a3975",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(docs, testset_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How significant is the usage of ChatGPT, with ...</td>\n",
              "      <td>[Introduction ChatGPT launched in November 202...</td>\n",
              "      <td>By July 2025, 18 billion messages were being s...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is Claude in the context of ChatGPT usage?</td>\n",
              "      <td>[Table 1: ChatGPT daily message counts (millio...</td>\n",
              "      <td>Claude is mentioned as a term in the context o...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ChatGPT use in jobs?</td>\n",
              "      <td>[Variation by Occupation Figure 23 presents va...</td>\n",
              "      <td>Variation by Occupation Figure 23 shows variat...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What does Seeking Information mean in ChatGPT ...</td>\n",
              "      <td>[Conclusion This paper studies the rapid growt...</td>\n",
              "      <td>Seeking Information is one of the three most c...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jun 2024 message volume vs Jun 2025 non-work m...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nMonth Non-Work (M) (%) Work (M) (%...</td>\n",
              "      <td>In June 2024, there were 451 million total mes...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How does ChatGPT usage vary across occupation ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nVariation by Occupation Figure 23 ...</td>\n",
              "      <td>ChatGPT usage varies significantly across occu...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does the rapid growth and widespread adopt...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
              "      <td>The rapid growth of ChatGPT, with over 700 mil...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>In June 2024 and June 2025, how did the growth...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nMonth Non-Work (M) (%) Work (M) (%...</td>\n",
              "      <td>According to the data, in June 2024, non-work ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Considering the rapid growth of ChatGPT usage ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nIntroduction ChatGPT launched in N...</td>\n",
              "      <td>By July 2025, approximately 70% of ChatGPT con...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How does the usage of ChatGPT in July 2025 ref...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nIntroduction ChatGPT launched in N...</td>\n",
              "      <td>By July 2025, ChatGPT had been used weekly by ...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>how many users 700 million users use ChatGPT f...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nIntroduction ChatGPT launched in N...</td>\n",
              "      <td>By July 2025, ChatGPT was used weekly by more ...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>when november 2022 chatgpt start and how many ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nIntroduction ChatGPT launched in N...</td>\n",
              "      <td>ChatGPT launched in November 2022, and by July...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0   How significant is the usage of ChatGPT, with ...   \n",
              "1     What is Claude in the context of ChatGPT usage?   \n",
              "2                                ChatGPT use in jobs?   \n",
              "3   What does Seeking Information mean in ChatGPT ...   \n",
              "4   Jun 2024 message volume vs Jun 2025 non-work m...   \n",
              "5   How does ChatGPT usage vary across occupation ...   \n",
              "6   How does the rapid growth and widespread adopt...   \n",
              "7   In June 2024 and June 2025, how did the growth...   \n",
              "8   Considering the rapid growth of ChatGPT usage ...   \n",
              "9   How does the usage of ChatGPT in July 2025 ref...   \n",
              "10  how many users 700 million users use ChatGPT f...   \n",
              "11  when november 2022 chatgpt start and how many ...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [Introduction ChatGPT launched in November 202...   \n",
              "1   [Table 1: ChatGPT daily message counts (millio...   \n",
              "2   [Variation by Occupation Figure 23 presents va...   \n",
              "3   [Conclusion This paper studies the rapid growt...   \n",
              "4   [<1-hop>\\n\\nMonth Non-Work (M) (%) Work (M) (%...   \n",
              "5   [<1-hop>\\n\\nVariation by Occupation Figure 23 ...   \n",
              "6   [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
              "7   [<1-hop>\\n\\nMonth Non-Work (M) (%) Work (M) (%...   \n",
              "8   [<1-hop>\\n\\nIntroduction ChatGPT launched in N...   \n",
              "9   [<1-hop>\\n\\nIntroduction ChatGPT launched in N...   \n",
              "10  [<1-hop>\\n\\nIntroduction ChatGPT launched in N...   \n",
              "11  [<1-hop>\\n\\nIntroduction ChatGPT launched in N...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   By July 2025, 18 billion messages were being s...   \n",
              "1   Claude is mentioned as a term in the context o...   \n",
              "2   Variation by Occupation Figure 23 shows variat...   \n",
              "3   Seeking Information is one of the three most c...   \n",
              "4   In June 2024, there were 451 million total mes...   \n",
              "5   ChatGPT usage varies significantly across occu...   \n",
              "6   The rapid growth of ChatGPT, with over 700 mil...   \n",
              "7   According to the data, in June 2024, non-work ...   \n",
              "8   By July 2025, approximately 70% of ChatGPT con...   \n",
              "9   By July 2025, ChatGPT had been used weekly by ...   \n",
              "10  By July 2025, ChatGPT was used weekly by more ...   \n",
              "11  ChatGPT launched in November 2022, and by July...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   multi_hop_abstract_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_abstract_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  \n",
              "11  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.to_pandas().to_csv(\"synthetic_testset.csv\", index=False)\n",
        "dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vSRr2MXk0P_"
      },
      "source": [
        "We'll need to provide our LangSmith API key, and set tracing to \"true\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLDUsLJg43k7"
      },
      "source": [
        "# ðŸ¤ BREAKOUT ROOM #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SLtk1GtnyoY"
      },
      "source": [
        "## Task 4: LangSmith Dataset\n",
        "\n",
        "Now we can move on to creating a dataset for LangSmith!\n",
        "\n",
        "First, we'll need to create a dataset on LangSmith using the `Client`!\n",
        "\n",
        "We'll name our Dataset to make it easy to work with later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLgm6OjvYSsm"
      },
      "outputs": [],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()\n",
        "\n",
        "dataset_name = \"Use Case Synthetic Data - AIE8\"\n",
        "\n",
        "langsmith_dataset = client.create_dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    description=\"Synthetic Data for Use Cases\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64SmXMBnzXWm"
      },
      "source": [
        "We'll iterate through the RAGAS created dataframe - and add each example to our created dataset!\n",
        "\n",
        "> NOTE: We need to conform the outputs to the expected format - which in this case is: `question` and `answer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nFQ6di_XnY7"
      },
      "outputs": [],
      "source": [
        "for data_row in dataset.to_pandas().iterrows():\n",
        "  client.create_example(\n",
        "      inputs={\n",
        "          \"question\": data_row[1][\"user_input\"]\n",
        "      },\n",
        "      outputs={\n",
        "          \"answer\": data_row[1][\"reference\"]\n",
        "      },\n",
        "      metadata={\n",
        "          \"context\": data_row[1][\"reference_contexts\"]\n",
        "      },\n",
        "      dataset_id=langsmith_dataset.id\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6EbQVyZq-2j"
      },
      "source": [
        "## Basic RAG Chain\n",
        "\n",
        "Time for some RAG!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4njbUAIsaYjB"
      },
      "outputs": [],
      "source": [
        "rag_documents = docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQorBy8H1AZR"
      },
      "source": [
        "To keep things simple, we'll just use LangChain's recursive character text splitter!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWo3Ajaragv1"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap = 50\n",
        ")\n",
        "\n",
        "rag_documents = text_splitter.split_documents(rag_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kghuTb9R01oO"
      },
      "source": [
        "We'll create our vectorstore using OpenAI's [`text-embedding-3-small`](https://platform.openai.com/docs/guides/embeddings/embedding-models) embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwfJCzP3aqKI"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpCLS-a01Ft2"
      },
      "source": [
        "As usual, we will power our RAG application with Qdrant!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58Ypj_NgbEsi"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    documents=rag_documents,\n",
        "    embedding=embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"Use Case RAG\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbKSjfSkbTYo"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxUOMaQX1K2N"
      },
      "source": [
        "To get the \"A\" in RAG, we'll provide a prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sLeY1oWbVqO"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_PROMPT = \"\"\"\\\n",
        "Given a provided context and question, you must answer the question based only on context.\n",
        "\n",
        "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
        "\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZnHDh4e1Ou5"
      },
      "source": [
        "As is usual: We'll be using `gpt-4.1-mini` for our RAG!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nx-ue1XbciV"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmTL6-pc1ZGz"
      },
      "source": [
        "Finally, we can set-up our RAG LCEL chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjWj0OLIbbFc"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
        "from langchain.schema import StrOutputParser\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "    | rag_prompt | llm | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WQ7bEweo4IIb",
        "outputId": "d161b269-f799-4920-d6ce-c202f6e783aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Based on the provided context, people are using AI, particularly generative AI like ChatGPT, for a variety of activities both at work and outside of work. These uses include performing workplace tasks by either augmenting or automating human labor, producing writing, software code, spreadsheets, and other digital products. People also use AI to seek information and advice, improve productivity, solve problems with AI as co-workers or co-pilots, and engage in self-expression such as relationships, personal reflection, games, and role play. Generative AI's flexibility allows it to be applied in many different ways across diverse tasks.\""
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke({\"question\" : \"What are people doing with AI these days?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9hBh5YPrdGJ"
      },
      "source": [
        "## LangSmith Evaluation Set-up\n",
        "\n",
        "We'll use OpenAI's GPT-4.1 as our evaluation LLM for our base Evaluators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfwPYdIkcvpF"
      },
      "outputs": [],
      "source": [
        "eval_llm = ChatOpenAI(model=\"gpt-4.1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b8pToKH2K28"
      },
      "source": [
        "We'll be using a number of evaluators - from LangSmith provided evaluators, to a few custom evaluators!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXSG-_ajckp6"
      },
      "outputs": [],
      "source": [
        "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
        "\n",
        "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\" : eval_llm})\n",
        "\n",
        "labeled_helpfulness_evaluator = LangChainStringEvaluator(\n",
        "    \"labeled_criteria\",\n",
        "    config={\n",
        "        \"criteria\": {\n",
        "            \"helpfulness\": (\n",
        "                \"Is this submission helpful to the user,\"\n",
        "                \" taking into account the correct reference answer?\"\n",
        "            )\n",
        "        },\n",
        "        \"llm\" : eval_llm\n",
        "    },\n",
        "    prepare_data=lambda run, example: {\n",
        "        \"prediction\": run.outputs[\"output\"],\n",
        "        \"reference\": example.outputs[\"answer\"],\n",
        "        \"input\": example.inputs[\"question\"],\n",
        "    }\n",
        ")\n",
        "\n",
        "dopeness_evaluator = LangChainStringEvaluator(\n",
        "    \"criteria\",\n",
        "    config={\n",
        "        \"criteria\": {\n",
        "            \"dopeness\": \"Is this response dope, lit, cool, or is it just a generic response?\",\n",
        "        },\n",
        "        \"llm\" : eval_llm\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0SQP_FoCetP"
      },
      "source": [
        "#### ðŸ—ï¸ Activity #2:\n",
        "\n",
        "Highlight what each evaluator is evaluating.\n",
        "\n",
        "##### âœ… Answer:\n",
        "\n",
        "- `qa_evaluator`: correctness of the LLM response to a user query or question\n",
        "- `labeled_helpfulness_evaluator`: helpsulness of the LLM response\n",
        "- `dopeness_evaluator`: how \"dope\" (lit, cool) the LLM response is"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R35sQMHVrnpl"
      },
      "source": [
        "## LangSmith Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "122b1bd1f0e9417a8dcb57d4eebe4d2e",
            "e0c233ad01604540a6c873f4a731982d",
            "e9a01115c75b499884f7e0ef32e9e599",
            "5faba4ad609448b2b49024add4ad3b8e",
            "ef25efa751304e4699910f1fbc14345f",
            "0b44cb0f8e34446c8dde668a75d3d8ad",
            "edaac6587b2d4bd5be52b89bb097f99f",
            "7cb241365f604419af454c1c28de197a",
            "9cf586576ff44dba86ba2eb389593c61",
            "849b5c95008541d49f1ceedf0a59ac60",
            "f3665a86662746c4ac7cb0796604781d"
          ]
        },
        "id": "t7t_Uz0tdumL",
        "outputId": "d684e218-294e-4dc3-c8de-a01d397f021c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for experiment: 'weary-idea-78' at:\n",
            "https://smith.langchain.com/o/bb9a3dd7-ec88-4998-a3cb-7a19da336bd6/datasets/c860f007-b15f-4ab5-b7a3-f878ec0967f2/compare?selectedSessions=8a19434f-539f-4cd0-bdf1-5664f7106f13\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cfc86a542e140d9ac4a0081e5f61a21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs.question</th>\n",
              "      <th>outputs.output</th>\n",
              "      <th>error</th>\n",
              "      <th>reference.answer</th>\n",
              "      <th>feedback.correctness</th>\n",
              "      <th>feedback.helpfulness</th>\n",
              "      <th>feedback.dopeness</th>\n",
              "      <th>execution_time</th>\n",
              "      <th>example_id</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>when november 2022 chatgpt start and how many ...</td>\n",
              "      <td>ChatGPT was released to the public on November...</td>\n",
              "      <td>None</td>\n",
              "      <td>ChatGPT launched in November 2022, and by July...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.802712</td>\n",
              "      <td>252cd427-19a1-4caa-9750-8a69d12ca792</td>\n",
              "      <td>28cefe55-2c28-4960-b570-8e2acb60a366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>how many users 700 million users use ChatGPT f...</td>\n",
              "      <td>Based on the context, the 700 million weekly a...</td>\n",
              "      <td>None</td>\n",
              "      <td>By July 2025, ChatGPT was used weekly by more ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.708007</td>\n",
              "      <td>9ba91298-9a7c-4614-b16f-ac918bfcee96</td>\n",
              "      <td>f5d48f14-66d4-46f7-9c68-68aa00eaf824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How does the usage of ChatGPT in July 2025 ref...</td>\n",
              "      <td>By July 2025, ChatGPT had been adopted by arou...</td>\n",
              "      <td>None</td>\n",
              "      <td>By July 2025, ChatGPT had been used weekly by ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.434548</td>\n",
              "      <td>e28a49ee-4b25-4600-857b-5cb89a2691a8</td>\n",
              "      <td>2163b65c-53dd-4f23-a002-4c89b21ea585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Considering the rapid growth of ChatGPT usage ...</td>\n",
              "      <td>By July 2025, non-work-related ChatGPT message...</td>\n",
              "      <td>None</td>\n",
              "      <td>By July 2025, approximately 70% of ChatGPT con...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3.002660</td>\n",
              "      <td>b892e263-476b-4e1b-870f-0efefa869575</td>\n",
              "      <td>aaaa9000-a13a-449e-a300-596b11d60346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In June 2024 and June 2025, how did the growth...</td>\n",
              "      <td>Based on the provided context:\\n\\n- The three ...</td>\n",
              "      <td>None</td>\n",
              "      <td>According to the data, in June 2024, non-work ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>9.531043</td>\n",
              "      <td>8d6eec9b-1079-4d86-b3ad-feb17755d1d1</td>\n",
              "      <td>211f4add-c9de-4536-9819-afec3b696566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How does the rapid growth and widespread adopt...</td>\n",
              "      <td>The rapid growth and widespread adoption of Ch...</td>\n",
              "      <td>None</td>\n",
              "      <td>The rapid growth of ChatGPT, with over 700 mil...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.744580</td>\n",
              "      <td>7c6da625-f27e-4823-bd7f-b8eb559b69ef</td>\n",
              "      <td>42766ec3-5293-4b1c-ac03-4b0b82c21fa9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does ChatGPT usage vary across occupation ...</td>\n",
              "      <td>ChatGPT usage varies across broad occupation c...</td>\n",
              "      <td>None</td>\n",
              "      <td>ChatGPT usage varies significantly across occu...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3.730170</td>\n",
              "      <td>b17c8070-a3d3-4848-9d38-b5c209e25443</td>\n",
              "      <td>3e472bf8-a8d2-4087-ba68-b655ca8d9ad8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Jun 2024 message volume vs Jun 2025 non-work m...</td>\n",
              "      <td>In June 2024, there were 238 million non-work ...</td>\n",
              "      <td>None</td>\n",
              "      <td>In June 2024, there were 451 million total mes...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.685718</td>\n",
              "      <td>2aaf188f-3b37-47ed-984d-dd9f8682a040</td>\n",
              "      <td>0f51f277-f99e-40be-b0ff-2c5084798920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What does Seeking Information mean in ChatGPT ...</td>\n",
              "      <td>Seeking Information in ChatGPT usage refers to...</td>\n",
              "      <td>None</td>\n",
              "      <td>Seeking Information is one of the three most c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.283763</td>\n",
              "      <td>526e5eba-10be-4ceb-b4bc-0c710f0ade09</td>\n",
              "      <td>fb78ecb0-2d26-4d55-8abb-6ad90d0b6a76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ChatGPT use in jobs?</td>\n",
              "      <td>ChatGPT usage at work is more common among use...</td>\n",
              "      <td>None</td>\n",
              "      <td>Variation by Occupation Figure 23 shows variat...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3.773399</td>\n",
              "      <td>729153ad-5076-46b7-a685-0a14cfdd4bae</td>\n",
              "      <td>0bf22845-c8f6-445c-895a-53b3d91e0d8d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What is Claude in the context of ChatGPT usage?</td>\n",
              "      <td>Based on the provided context, Claude is menti...</td>\n",
              "      <td>None</td>\n",
              "      <td>Claude is mentioned as a term in the context o...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.759470</td>\n",
              "      <td>c6d2db71-0d6b-4aa5-8bde-2fc21394d388</td>\n",
              "      <td>0f800f07-f30a-458d-bd92-04b152cc3022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How significant is the usage of ChatGPT, with ...</td>\n",
              "      <td>The usage of ChatGPT, with 18 billion messages...</td>\n",
              "      <td>None</td>\n",
              "      <td>By July 2025, 18 billion messages were being s...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.292121</td>\n",
              "      <td>18936cd1-30fa-4a5b-8b73-0ab74776562f</td>\n",
              "      <td>10c7a9d8-6ab4-45c0-8796-7db1537003c2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "<ExperimentResults weary-idea-78>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(\n",
        "    rag_chain.invoke,\n",
        "    data=dataset_name,\n",
        "    evaluators=[\n",
        "        qa_evaluator,\n",
        "        labeled_helpfulness_evaluator,\n",
        "        dopeness_evaluator\n",
        "    ],\n",
        "    metadata={\"revision_id\": \"default_chain_init\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq7fCVinrpI4"
      },
      "source": [
        "## Dope-ifying Our Application\n",
        "\n",
        "We'll be making a few changes to our RAG chain to increase its performance on our SDG evaluation test dataset!\n",
        "\n",
        "- Include a \"dope\" prompt augmentation\n",
        "- Use larger chunks\n",
        "- Improve the retriever model to: `text-embedding-3-large`\n",
        "\n",
        "Let's see how this changes our evaluation!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "z56pXwyUgFUt"
      },
      "outputs": [],
      "source": [
        "DOPENESS_RAG_PROMPT = \"\"\"\\\n",
        "Given a provided context and question, you must answer the question based only on context.\n",
        "\n",
        "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
        "\n",
        "Make your answer rad, ensure high levels of dopeness. Do not be generic, or give generic responses.\n",
        "\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "dopeness_rag_prompt = ChatPromptTemplate.from_template(DOPENESS_RAG_PROMPT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "rZLcTstJgfv5"
      },
      "outputs": [],
      "source": [
        "rag_documents = docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "-LYsyirngj6n"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap = 50\n",
        ")\n",
        "\n",
        "rag_documents = text_splitter.split_documents(rag_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spldiPuTCzDO"
      },
      "source": [
        "#### â“Question #2:\n",
        "\n",
        "Why would modifying our chunk size modify the performance of our application?\n",
        "\n",
        "##### âœ… Answer:\n",
        "With bigger chuncks our embeddigns can capture more meaning as each chunck contain more context/information. But it is important to figure it out an optimal size for the type of document in each use case scenario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "b9MI2Bm2go1r"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBbjG6cKC8BQ"
      },
      "source": [
        "#### â“Question #3:\n",
        "\n",
        "Why would modifying our embedding model modify the performance of our application?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "hVUY25FKgxXx"
      },
      "outputs": [],
      "source": [
        "vectorstore = Qdrant.from_documents(\n",
        "    documents=rag_documents,\n",
        "    embedding=embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"Use Case RAG Docs\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "Q4TOZNYIg2v1"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqYGFrnKDB91"
      },
      "source": [
        "Setting up our new and improved DOPE RAG CHAIN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "HqnTqeXMhAdx"
      },
      "outputs": [],
      "source": [
        "dopeness_rag_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "    | dopeness_rag_prompt | llm | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21pTxoqJDI1Y"
      },
      "source": [
        "Let's test it on the same output that we saw before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "OfZZ3MoN3fKv",
        "outputId": "d65722dd-92c2-4e4e-9cca-c42ee6f3f208"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Alright, letâ€™s crank that insight dial to 11 and dive into this AI-money-making magic based purely on the rad context you dropped!\\n\\nPeople arenâ€™t just using AI like ChatGPT to push buttons and get basic tasks doneâ€”theyâ€™re flexing it as a **research assistant and decision-support co-pilot** in the workplace. This isnâ€™t about AI replacing jobs but supercharging *how* humans make decisions and crank up productivity, especially in brain-heavy, knowledge-intensive gigs. \\n\\nThat means AIâ€™s beast mode is in:\\n- **Advising and brainstorming** to make smarter work moves.\\n- **Boosting output** by giving users sharper info and guidance so they make killer decisions that pay dividends.\\n- And since knowledge work is a cash cow driven by decision quality, AI basically levels up your economic hustle by juicing your cognitive horsepower.\\n\\nPlus, the economics nerds Collis and Brynjolfsson (2025) put some wild numbers on this vibe â€” folks would shell out nearly a hundred bucks a month just to keep AI in their toolkit, showing how valuable this smart sidekick is for boosting income streams and work efficiency.\\n\\nSo bottom line: **People monetize AI by tapping it as a knowledge sidekick and decision-making amplifierâ€”making smarter moves, hustling harder, and ultimately stacking more paper through better work outcomes.** Thatâ€™s the AI game-changer for making money right now.\\n\\nBoom, AI isnâ€™t just a tool â€” itâ€™s the dopest wingman in the cash chase!'"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dopeness_rag_chain.invoke({\"question\" : \"How are people using AI to make money?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpj7v1inDLnQ"
      },
      "source": [
        "Finally, we can evaluate the new chain on the same test set!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Use Case Synthetic Data - AIE8'"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "bf8dcc0895054529af356da401c513f6",
            "7dce19ac55264f2b88a0e4730e55867b",
            "2a0755d4476543feb4a64538e3e37213",
            "158212a630f04cbd884c937f2f60f5c8",
            "11c7f66acc1d45be9517d0addf49331e",
            "ddffd834e09940a4bd3874c3f39b4e21",
            "ef63c3b2d51e452da03cdae5d9b034be",
            "c20b539cd70b4ba99601ad1d69fd9cec",
            "a6d681eeafa44d18b933a4c5dec88382",
            "d1d54ccd56494c4d831f71b416a1f880",
            "530f696feefe499da08c6312047379b2"
          ]
        },
        "id": "Dx11S2b-hIM8",
        "outputId": "d3a3ea78-aa32-4bd2-8c2a-d0d0303695c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for experiment: 'damp-shade-24' at:\n",
            "https://smith.langchain.com/o/bb9a3dd7-ec88-4998-a3cb-7a19da336bd6/datasets/c860f007-b15f-4ab5-b7a3-f878ec0967f2/compare?selectedSessions=3775cda9-63fa-4cd8-9efd-184d7304fb6e\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7da8b7c6c8f417e88f6912a13f89ab1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs.question</th>\n",
              "      <th>outputs.output</th>\n",
              "      <th>error</th>\n",
              "      <th>reference.answer</th>\n",
              "      <th>feedback.correctness</th>\n",
              "      <th>feedback.helpfulness</th>\n",
              "      <th>feedback.dopeness</th>\n",
              "      <th>execution_time</th>\n",
              "      <th>example_id</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>when november 2022 chatgpt start and how many ...</td>\n",
              "      <td>Oh yeah, diving into the chronicles of ChatGPT...</td>\n",
              "      <td>None</td>\n",
              "      <td>ChatGPT launched in November 2022, and by July...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.596144</td>\n",
              "      <td>252cd427-19a1-4caa-9750-8a69d12ca792</td>\n",
              "      <td>fca7cf54-7a4b-45eb-adb5-a0134dea0950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>how many users 700 million users use ChatGPT f...</td>\n",
              "      <td>Alright, letâ€™s drop some straight-up knowledge...</td>\n",
              "      <td>None</td>\n",
              "      <td>By July 2025, ChatGPT was used weekly by more ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.890149</td>\n",
              "      <td>9ba91298-9a7c-4614-b16f-ac918bfcee96</td>\n",
              "      <td>cbdfa4af-6a83-4a83-babb-ceb76c7a8e8c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How does the usage of ChatGPT in July 2025 ref...</td>\n",
              "      <td>Oh, buckle up for this stellar ride through Ch...</td>\n",
              "      <td>None</td>\n",
              "      <td>By July 2025, ChatGPT had been used weekly by ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6.613110</td>\n",
              "      <td>e28a49ee-4b25-4600-857b-5cb89a2691a8</td>\n",
              "      <td>957915bf-7264-43f5-ada1-0bd4c360c850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Considering the rapid growth of ChatGPT usage ...</td>\n",
              "      <td>Yo, by July 2025, non-work-related ChatGPT mes...</td>\n",
              "      <td>None</td>\n",
              "      <td>By July 2025, approximately 70% of ChatGPT con...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.935129</td>\n",
              "      <td>b892e263-476b-4e1b-870f-0efefa869575</td>\n",
              "      <td>e65adb6d-f49e-4b4c-a167-5e244ac99e2b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In June 2024 and June 2025, how did the growth...</td>\n",
              "      <td>Yo, letâ€™s break down this ChatGPT saga like a ...</td>\n",
              "      <td>None</td>\n",
              "      <td>According to the data, in June 2024, non-work ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7.712247</td>\n",
              "      <td>8d6eec9b-1079-4d86-b3ad-feb17755d1d1</td>\n",
              "      <td>4a26a9a0-7879-4ea8-bfe7-d1993d876a5f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How does the rapid growth and widespread adopt...</td>\n",
              "      <td>Alright, buckle upâ€”hereâ€™s the rad scoop straig...</td>\n",
              "      <td>None</td>\n",
              "      <td>The rapid growth of ChatGPT, with over 700 mil...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5.253360</td>\n",
              "      <td>7c6da625-f27e-4823-bd7f-b8eb559b69ef</td>\n",
              "      <td>a3dc019d-1284-4a55-983e-00616ddb0d71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does ChatGPT usage vary across occupation ...</td>\n",
              "      <td>Alright, buckle up â€” hereâ€™s the lowdown on Cha...</td>\n",
              "      <td>None</td>\n",
              "      <td>ChatGPT usage varies significantly across occu...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8.785578</td>\n",
              "      <td>b17c8070-a3d3-4848-9d38-b5c209e25443</td>\n",
              "      <td>729a92b1-b7bf-4ba0-87ac-1586e84eee6b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Jun 2024 message volume vs Jun 2025 non-work m...</td>\n",
              "      <td>Alright, letâ€™s dive into this epic ChatGPT mes...</td>\n",
              "      <td>None</td>\n",
              "      <td>In June 2024, there were 451 million total mes...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6.617192</td>\n",
              "      <td>2aaf188f-3b37-47ed-984d-dd9f8682a040</td>\n",
              "      <td>390de5ec-2b0d-4c6e-92d1-8edc5e7da039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What does Seeking Information mean in ChatGPT ...</td>\n",
              "      <td>Alright, buckle up for some top-tier AI knowle...</td>\n",
              "      <td>None</td>\n",
              "      <td>Seeking Information is one of the three most c...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.777026</td>\n",
              "      <td>526e5eba-10be-4ceb-b4bc-0c710f0ade09</td>\n",
              "      <td>9d18202c-44e1-4519-b8c4-c43fdc6a7772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ChatGPT use in jobs?</td>\n",
              "      <td>Alright, buckle up because hereâ€™s the rad lowd...</td>\n",
              "      <td>None</td>\n",
              "      <td>Variation by Occupation Figure 23 shows variat...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.447190</td>\n",
              "      <td>729153ad-5076-46b7-a685-0a14cfdd4bae</td>\n",
              "      <td>a1648c31-86bd-4762-a18d-9f665972f4b1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What is Claude in the context of ChatGPT usage?</td>\n",
              "      <td>Yo, buckle up for some AI-realness! Claude is ...</td>\n",
              "      <td>None</td>\n",
              "      <td>Claude is mentioned as a term in the context o...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.822371</td>\n",
              "      <td>c6d2db71-0d6b-4aa5-8bde-2fc21394d388</td>\n",
              "      <td>d2574b6c-ba77-49c1-8f97-e2181981fb83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How significant is the usage of ChatGPT, with ...</td>\n",
              "      <td>Yo, brace yourself for this cosmic statâ€”ChatGP...</td>\n",
              "      <td>None</td>\n",
              "      <td>By July 2025, 18 billion messages were being s...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.207090</td>\n",
              "      <td>18936cd1-30fa-4a5b-8b73-0ab74776562f</td>\n",
              "      <td>e2fac762-b413-422e-ab6e-75682d728142</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "<ExperimentResults damp-shade-24>"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(\n",
        "    dopeness_rag_chain.invoke,\n",
        "    data=dataset_name,\n",
        "    evaluators=[\n",
        "        qa_evaluator,\n",
        "        labeled_helpfulness_evaluator,\n",
        "        dopeness_evaluator\n",
        "    ],\n",
        "    metadata={\"revision_id\": \"dopeness_rag_chain\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C7migvlDPZT"
      },
      "source": [
        "#### ðŸ—ï¸ Activity #3:\n",
        "\n",
        "Provide a screenshot of the difference between the two chains, and explain why you believe certain metrics changed in certain ways.\n",
        "\n",
        "##### âœ… Answer:\n",
        "The stats below show the difference between two evaluation runs shwoing a hugge difference in the \"dopeness\" criteria evaluator. \n",
        "\n",
        "![](./langsmith-evals-comparison.png)\n",
        "\n",
        "The first experiment run (labeled as \"**weary-idea-78**\") shows the dopeness evaluation with zeroed score for all queries.\n",
        "\n",
        "![](./langsmith-bad-dopeness-eval.png)\n",
        "\n",
        "After applying some changes in th RAG chain, like: \n",
        " * using bigger chuncks and a bigger embedding models; \n",
        " * rewording the prompt;\n",
        "\n",
        "we can see in the second experiment (labeled as \"**damp-shade-24**\") a significant change on how the dopeness evaluator gets scored.\n",
        "\n",
        "![](./langsmith-good-dopness-eval.png)\n",
        "\n",
        "Based on the results from the second experiment we can infer that the changes applied to the RAG chain helped the model better understand the context from the \"dopeness perspective\".  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07ab3dc0790241bbb85a7f488a42ef8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7710c7377cbc4c30b55b28b4bc99e88f",
              "IPY_MODEL_41bdd49fab5f4826959d0d50663ff539",
              "IPY_MODEL_60168d85131d4afc99d55d61ab954ee6"
            ],
            "layout": "IPY_MODEL_9edf898aeeab40dda9b9475395776521"
          }
        },
        "095f680d37a3430fb82d223615662db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b44cb0f8e34446c8dde668a75d3d8ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10df31709059484c99f102453d780473": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1160a44dc18e47b0890f70c40eaa7eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11c7f66acc1d45be9517d0addf49331e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "122b1bd1f0e9417a8dcb57d4eebe4d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0c233ad01604540a6c873f4a731982d",
              "IPY_MODEL_e9a01115c75b499884f7e0ef32e9e599",
              "IPY_MODEL_5faba4ad609448b2b49024add4ad3b8e"
            ],
            "layout": "IPY_MODEL_ef25efa751304e4699910f1fbc14345f"
          }
        },
        "158212a630f04cbd884c937f2f60f5c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1d54ccd56494c4d831f71b416a1f880",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_530f696feefe499da08c6312047379b2",
            "value": "â€‡20/?â€‡[01:43&lt;00:00,â€‡â€‡5.25s/it]"
          }
        },
        "23863bc37a8645029934b8c106622c51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2508d229935744cbb5fc340222e2d660": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a0755d4476543feb4a64538e3e37213": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c20b539cd70b4ba99601ad1d69fd9cec",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6d681eeafa44d18b933a4c5dec88382",
            "value": 1
          }
        },
        "33f063017b7c4c7fa8cbafc89674350b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6864c81e2bcf459bbaf5acbb36bdfcbe",
              "IPY_MODEL_59d6e269eadf429a924f6f79bc8ba4ba",
              "IPY_MODEL_ca791fc471e34b9da2f9070fc1053c0f"
            ],
            "layout": "IPY_MODEL_8baf0ed3d0f743f294e07f2b5407e820"
          }
        },
        "3a8537e37fc14fd9b16ca0ceee4fede6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41bdd49fab5f4826959d0d50663ff539": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eb8b2e3262c45248708a2082c366f0a",
            "max": 64,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_095f680d37a3430fb82d223615662db5",
            "value": 64
          }
        },
        "530f696feefe499da08c6312047379b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59d6e269eadf429a924f6f79bc8ba4ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_890e0dd7fa524ceca1e805cb6253ee71",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61b52ff459214129b8f7e6d67b192b78",
            "value": 20
          }
        },
        "5ab5f08afa5841709aedb2f78a52a11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c2fda99d4204d85b1bf7ad354fd58d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5faba4ad609448b2b49024add4ad3b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_849b5c95008541d49f1ceedf0a59ac60",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f3665a86662746c4ac7cb0796604781d",
            "value": "â€‡20/?â€‡[01:27&lt;00:00,â€‡â€‡6.45s/it]"
          }
        },
        "60168d85131d4afc99d55d61ab954ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a8537e37fc14fd9b16ca0ceee4fede6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1160a44dc18e47b0890f70c40eaa7eb0",
            "value": "â€‡61/64â€‡[00:02&lt;00:00,â€‡23.36it/s]"
          }
        },
        "61b52ff459214129b8f7e6d67b192b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6864c81e2bcf459bbaf5acbb36bdfcbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10df31709059484c99f102453d780473",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2508d229935744cbb5fc340222e2d660",
            "value": "Generating:â€‡100%"
          }
        },
        "6eb8b2e3262c45248708a2082c366f0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7710c7377cbc4c30b55b28b4bc99e88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c2fda99d4204d85b1bf7ad354fd58d4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_93cd4d35c5fd41f5904ca1d52d1f52a8",
            "value": "embeddingâ€‡nodes:â€‡â€‡95%"
          }
        },
        "7cb241365f604419af454c1c28de197a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7dce19ac55264f2b88a0e4730e55867b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddffd834e09940a4bd3874c3f39b4e21",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ef63c3b2d51e452da03cdae5d9b034be",
            "value": ""
          }
        },
        "849b5c95008541d49f1ceedf0a59ac60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "890e0dd7fa524ceca1e805cb6253ee71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8baf0ed3d0f743f294e07f2b5407e820": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93cd4d35c5fd41f5904ca1d52d1f52a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cf586576ff44dba86ba2eb389593c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9edf898aeeab40dda9b9475395776521": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "a6d681eeafa44d18b933a4c5dec88382": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf8dcc0895054529af356da401c513f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7dce19ac55264f2b88a0e4730e55867b",
              "IPY_MODEL_2a0755d4476543feb4a64538e3e37213",
              "IPY_MODEL_158212a630f04cbd884c937f2f60f5c8"
            ],
            "layout": "IPY_MODEL_11c7f66acc1d45be9517d0addf49331e"
          }
        },
        "c20b539cd70b4ba99601ad1d69fd9cec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ca791fc471e34b9da2f9070fc1053c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23863bc37a8645029934b8c106622c51",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5ab5f08afa5841709aedb2f78a52a11c",
            "value": "â€‡20/20â€‡[00:52&lt;00:00,â€‡â€‡4.50s/it]"
          }
        },
        "d1d54ccd56494c4d831f71b416a1f880": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddffd834e09940a4bd3874c3f39b4e21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0c233ad01604540a6c873f4a731982d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b44cb0f8e34446c8dde668a75d3d8ad",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_edaac6587b2d4bd5be52b89bb097f99f",
            "value": ""
          }
        },
        "e9a01115c75b499884f7e0ef32e9e599": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cb241365f604419af454c1c28de197a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9cf586576ff44dba86ba2eb389593c61",
            "value": 1
          }
        },
        "edaac6587b2d4bd5be52b89bb097f99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef25efa751304e4699910f1fbc14345f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef63c3b2d51e452da03cdae5d9b034be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3665a86662746c4ac7cb0796604781d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "state": {}
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
